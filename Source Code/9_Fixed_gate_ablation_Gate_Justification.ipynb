{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d25afba95657403b90f8f138d3bc44f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6201c20884db4cddad3f7af4f0d3eab2",
              "IPY_MODEL_71e7ca5015414a259249f64bc2306c54",
              "IPY_MODEL_bda117661cc14afcbd112d76942c9d5c"
            ],
            "layout": "IPY_MODEL_f29e0d3684204b14b0b216938082565c"
          }
        },
        "6201c20884db4cddad3f7af4f0d3eab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fab4181b25a44bd38b21897639952df1",
            "placeholder": "​",
            "style": "IPY_MODEL_996f28628c3f46ceb23a2878fe21801e",
            "value": "model.safetensors: 100%"
          }
        },
        "71e7ca5015414a259249f64bc2306c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177635226f5542128d099eca71a066da",
            "max": 101484732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b31ab1fa866b4de79b3caad022a56931",
            "value": 101484732
          }
        },
        "bda117661cc14afcbd112d76942c9d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed22f8a922e4d6cbe1628171d8d4b2c",
            "placeholder": "​",
            "style": "IPY_MODEL_79255e810fdb42928314471152961be6",
            "value": " 101M/101M [00:01&lt;00:00, 70.9MB/s]"
          }
        },
        "f29e0d3684204b14b0b216938082565c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab4181b25a44bd38b21897639952df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996f28628c3f46ceb23a2878fe21801e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "177635226f5542128d099eca71a066da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b31ab1fa866b4de79b3caad022a56931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aed22f8a922e4d6cbe1628171d8d4b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79255e810fdb42928314471152961be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fixed-gate ablation (to prove that “adaptive gating” matters)\n",
        "\n",
        "Run the same training/eval but force:\n",
        "\n",
        "g0=0.5, g1=0.5, g2=0.5 (constant)\n",
        "Compare vs full model.\n",
        "If full > fixed → your gains come from learned gating, not just having two paths."
      ],
      "metadata": {
        "id": "lFJPvgOrQVg1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605,
          "referenced_widgets": [
            "d25afba95657403b90f8f138d3bc44f7",
            "6201c20884db4cddad3f7af4f0d3eab2",
            "71e7ca5015414a259249f64bc2306c54",
            "bda117661cc14afcbd112d76942c9d5c",
            "f29e0d3684204b14b0b216938082565c",
            "fab4181b25a44bd38b21897639952df1",
            "996f28628c3f46ceb23a2878fe21801e",
            "177635226f5542128d099eca71a066da",
            "b31ab1fa866b4de79b3caad022a56931",
            "aed22f8a922e4d6cbe1628171d8d4b2c",
            "79255e810fdb42928314471152961be6"
          ]
        },
        "id": "o8V_N2R_QUVS",
        "outputId": "2b36be36-3385-416e-83ac-9b26ebffdf4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/101M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d25afba95657403b90f8f138d3bc44f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           setting split           dataset       acc  precision_macro  \\\n",
            "0  fixed_gates_0.5   VAL  ds1+ds2 weighted  0.932070         0.778172   \n",
            "1  fixed_gates_0.5  TEST               ds1  0.938053         0.941976   \n",
            "2  fixed_gates_0.5  TEST               ds2  0.937441         0.936130   \n",
            "3  fixed_gates_0.5  TEST   global weighted  0.937549         0.937162   \n",
            "\n",
            "   recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  \\\n",
            "0      0.940230  0.789071            0.972431         0.932070     0.947113   \n",
            "1      0.934708  0.934669            0.942502         0.938053     0.936798   \n",
            "2      0.933919  0.933560            0.939898         0.937441     0.937307   \n",
            "3      0.934058  0.933756            0.940358         0.937549     0.937217   \n",
            "\n",
            "   log_loss  auc_roc_macro_ovr   loss_ce  eval_time_s  \n",
            "0  0.238275                NaN  0.238878     2.869883  \n",
            "1  0.221698           0.990906  0.219100     2.738322  \n",
            "2  0.223606           0.989408  0.224826     7.678782  \n",
            "3  0.223269           0.989672  0.223816     6.807163  \n",
            "Saved: /content/outputs/fixed_gates_val_test_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import subprocess\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    log_loss,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "\n",
        "def pip_install(pkg: str):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# -------------------------\n",
        "# Configuration\n",
        "# -------------------------\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "CSV_PATH = os.path.join(OUTDIR, \"fixed_gates_val_test_metrics.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = (x - mu) / sd\n",
        "        x0 = x0.clamp(-self.tau, self.tau)\n",
        "\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) +\n",
        "            0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None, []\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            ) for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class PVTv2B2_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            \"pvt_v2_b2\",\n",
        "            pretrained=pretrained,\n",
        "            features_only=True,\n",
        "            out_indices=(0, 1, 2, 3),\n",
        "        )\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        # Constant gates only: g0 = g1 = g2 = 0.5\n",
        "        x0 = 0.5 * x_raw_n + 0.5 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "        f_mid = 0.5 * f0 + 0.5 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        t_final = 0.5 * t_mid + 0.5 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor(\n",
        "            [\n",
        "                preproc_module.gamma,\n",
        "                preproc_module.alpha,\n",
        "                preproc_module.beta,\n",
        "                preproc_module.tau,\n",
        "                float(preproc_module.blur_k) / 7.0,\n",
        "                preproc_module.sharpen,\n",
        "                preproc_module.denoise,\n",
        "            ],\n",
        "            device=DEVICE,\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        out[\"auc_roc_macro_ovr\"] = np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        return {\n",
        "            \"acc\": np.nan,\n",
        "            \"precision_macro\": np.nan,\n",
        "            \"recall_macro\": np.nan,\n",
        "            \"f1_macro\": np.nan,\n",
        "            \"precision_weighted\": np.nan,\n",
        "            \"recall_weighted\": np.nan,\n",
        "            \"f1_weighted\": np.nan,\n",
        "            \"log_loss\": np.nan,\n",
        "            \"auc_roc_macro_ovr\": np.nan,\n",
        "            \"loss_ce\": np.nan,\n",
        "            \"eval_time_s\": float(time.time() - t0),\n",
        "        }\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader, max_candidates=10):\n",
        "    if not pool:\n",
        "        return None\n",
        "    cand = pool[:max_candidates]\n",
        "    best, best_acc = None, -1\n",
        "    for th in cand:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(metric_triplets: List[Tuple[int, dict, int]]):\n",
        "    if not metric_triplets:\n",
        "        return {}\n",
        "    total = sum(w for _, _, w in metric_triplets)\n",
        "    keys = metric_triplets[0][1].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[1].get(k, np.nan) for m in metric_triplets]\n",
        "        wts = [m[2] for m in metric_triplets]\n",
        "        out[k] = float(np.average(vals, weights=wts)) if total > 0 else np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "def prepare_data():\n",
        "    ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "    ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "    req1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "    req2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "    ds1_root = find_root_with_required_class_dirs(ds1_path, req1, prefer_raw=True)\n",
        "    ds2_root = find_root_with_required_class_dirs(ds2_path, req2, prefer_raw=False)\n",
        "    if ds1_root is None or ds2_root is None:\n",
        "        raise RuntimeError(\"Dataset roots not found.\")\n",
        "\n",
        "    df1 = enforce_labels(build_df_from_root(ds1_root, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "    df2 = enforce_labels(build_df_from_root(ds2_root, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "    train1, val1, test1 = split_dataset(df1)\n",
        "    train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "    n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "    client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "    client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "    client_splits = []\n",
        "    for k in range(n_per_ds):\n",
        "        tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "        client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "    for k in range(n_per_ds):\n",
        "        tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "        client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "    client_test_splits = []\n",
        "    for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "        idxs = list(range(len(test_df)))\n",
        "        random.shuffle(idxs)\n",
        "        split = np.array_split(idxs, n_per_ds)\n",
        "        for k in range(n_per_ds):\n",
        "            client_test_splits.append((ds_name, k, base_gid + k, split[k].tolist()))\n",
        "\n",
        "    client_loaders = []\n",
        "    for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "        df_src = train1 if ds_name == \"ds1\" else train2\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "\n",
        "        sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "        tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "        tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "        val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:max(1, min(len(tr_idx), CFG[\"batch_size\"]))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "        client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "    client_test_loaders = []\n",
        "    for ds_name, local_id, gid, test_idx in client_test_splits:\n",
        "        df_src = test1 if ds_name == \"ds1\" else test2\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(df_src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "        client_test_loaders.append((ds_name, local_id, gid, t_loader))\n",
        "\n",
        "    counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "    counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "\n",
        "    return {\n",
        "        \"client_loaders\": client_loaders,\n",
        "        \"client_test_loaders\": client_test_loaders,\n",
        "        \"n_per_ds\": n_per_ds,\n",
        "        \"counts\": counts1 + counts2,\n",
        "        \"test1_len\": len(test1),\n",
        "        \"test2_len\": len(test2),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_experiment(data_bundle, setting_name: str = \"fixed_gates_0.5\"):\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    client_loaders = data_bundle[\"client_loaders\"]\n",
        "    client_test_loaders = data_bundle[\"client_test_loaders\"]\n",
        "    n_per_ds = data_bundle[\"n_per_ds\"]\n",
        "\n",
        "    model = PVTv2B2_MultiScale(\n",
        "        num_classes=NUM_CLASSES,\n",
        "        pretrained=True,\n",
        "        head_dropout=CFG[\"head_dropout\"],\n",
        "        cond_dim=CFG[\"cond_dim\"],\n",
        "        num_clients=CFG[\"clients_total\"],\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    set_trainable_for_round(model, rnd=1)\n",
        "\n",
        "    backbone_frozen = model.backbone.eval()\n",
        "    for p in backbone_frozen.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    counts = data_bundle[\"counts\"]\n",
        "    w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "    w = w / max(1e-6, w.mean())\n",
        "    class_w = torch.tensor(w, device=DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "    scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "    elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "    best_global_acc = -1.0\n",
        "    best_model_state = None\n",
        "    best_theta_ds1 = None\n",
        "    best_theta_ds2 = None\n",
        "\n",
        "    for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "        local_models = []\n",
        "        local_weights = []\n",
        "        local_val_rows = []\n",
        "\n",
        "        for k in range(CFG[\"clients_total\"]):\n",
        "            tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "            ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "            elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "            if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "                best_theta, top_thetas = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "                elite_pool.extend(top_thetas)\n",
        "                elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "                pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "            else:\n",
        "                pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "            if ds_name == \"ds1\":\n",
        "                elite_pool_ds1 = elite_pool\n",
        "            else:\n",
        "                elite_pool_ds2 = elite_pool\n",
        "\n",
        "            local_model = PVTv2B2_MultiScale(\n",
        "                num_classes=NUM_CLASSES,\n",
        "                pretrained=False,\n",
        "                head_dropout=CFG[\"head_dropout\"],\n",
        "                cond_dim=CFG[\"cond_dim\"],\n",
        "                num_clients=CFG[\"clients_total\"],\n",
        "            ).to(DEVICE)\n",
        "            local_model.load_state_dict(model.state_dict(), strict=True)\n",
        "\n",
        "            set_trainable_for_round(local_model, rnd=rnd)\n",
        "            opt = make_optimizer(local_model)\n",
        "            total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "            warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "            scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "            for _ in range(CFG[\"local_epochs\"]):\n",
        "                train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, model, scheduler, scaler)\n",
        "\n",
        "            met_loc = evaluate_full(local_model, val_loader, pre_k)\n",
        "            local_val_rows.append((k, met_loc, len(val_loader.dataset)))\n",
        "\n",
        "            local_models.append(local_model)\n",
        "            local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "        wsum = sum(local_weights)\n",
        "        weights = [w / wsum for w in local_weights]\n",
        "        trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "        fedavg_update(model, local_models, weights, trainable_names)\n",
        "\n",
        "        val_best = weighted_aggregate(local_val_rows)\n",
        "        if np.isfinite(val_best[\"acc\"]) and val_best[\"acc\"] > best_global_acc:\n",
        "            best_global_acc = float(val_best[\"acc\"])\n",
        "            best_model_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "            best_theta_ds1 = pick_best_theta_from_pool(model, elite_pool_ds1, client_loaders[0][2])\n",
        "        if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "            best_theta_ds2 = pick_best_theta_from_pool(model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "    pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if best_theta_ds1 is not None else nn.Identity().to(DEVICE)\n",
        "    pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if best_theta_ds2 is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "    val_metrics_clients = []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        _, _, val_loader = client_loaders[k]\n",
        "        pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "        met = evaluate_full(model, val_loader, pre)\n",
        "        val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "    val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "    def eval_test_per_dataset(ds_name):\n",
        "        mets = []\n",
        "        for ds, _, _, t_loader in client_test_loaders:\n",
        "            if ds != ds_name:\n",
        "                continue\n",
        "            pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "            met = evaluate_full(model, t_loader, pre)\n",
        "            mets.append((0, met, len(t_loader.dataset)))\n",
        "        return weighted_aggregate(mets)\n",
        "\n",
        "    test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "    test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "    global_test = weighted_aggregate([\n",
        "        (0, test_ds1, data_bundle[\"test1_len\"]),\n",
        "        (1, test_ds2, data_bundle[\"test2_len\"]),\n",
        "    ])\n",
        "\n",
        "    metric_cols = [\n",
        "        \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"precision_weighted\",\n",
        "        \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\"\n",
        "    ]\n",
        "\n",
        "    def row(split, dataset, m):\n",
        "        r = {\"setting\": setting_name, \"split\": split, \"dataset\": dataset}\n",
        "        for c in metric_cols:\n",
        "            r[c] = float(m.get(c, np.nan)) if isinstance(m, dict) else np.nan\n",
        "        return r\n",
        "\n",
        "    return [\n",
        "        row(\"VAL\", \"ds1+ds2 weighted\", val_best),\n",
        "        row(\"TEST\", \"ds1\", test_ds1),\n",
        "        row(\"TEST\", \"ds2\", test_ds2),\n",
        "        row(\"TEST\", \"global weighted\", global_test),\n",
        "    ]\n",
        "\n",
        "\n",
        "def main():\n",
        "    data_bundle = prepare_data()\n",
        "\n",
        "    rows = []\n",
        "    rows.extend(run_experiment(data_bundle, setting_name=\"fixed_gates_0.5\"))\n",
        "\n",
        "    out_df = pd.DataFrame(rows, columns=[\n",
        "        \"setting\", \"split\", \"dataset\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "        \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"auc_roc_macro_ovr\",\n",
        "        \"loss_ce\", \"eval_time_s\"\n",
        "    ])\n",
        "\n",
        "    out_df.to_csv(CSV_PATH, index=False)\n",
        "    print(out_df)\n",
        "    print(f\"Saved: {CSV_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}