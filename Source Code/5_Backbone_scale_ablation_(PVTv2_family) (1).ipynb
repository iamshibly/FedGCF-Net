{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec97742fe3cb4f318f979d6adde89749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf632fc6b0ca4cf9b60a681ac29f8bf6",
              "IPY_MODEL_d9140c703f0e40008a97c4a0bc621909",
              "IPY_MODEL_36b8633a364f4fcb8cb1a5c4c5e2cff1"
            ],
            "layout": "IPY_MODEL_6da50e3584d0415dbc716661426da28e"
          }
        },
        "cf632fc6b0ca4cf9b60a681ac29f8bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf5cba43a9d478ba9fe403a3698fa49",
            "placeholder": "​",
            "style": "IPY_MODEL_62f6d162cd99406b98e135e046109510",
            "value": "model.safetensors: 100%"
          }
        },
        "d9140c703f0e40008a97c4a0bc621909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92aaa368a7c6460d80ccb125adb52a23",
            "max": 14684396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7030b13506164961ac7c650e4e932e4b",
            "value": 14684396
          }
        },
        "36b8633a364f4fcb8cb1a5c4c5e2cff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a9f98b3ff284073ad7544d08df80ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_0aa8c2986caa4b75bda3be9798bfa7ef",
            "value": " 14.7M/14.7M [00:00&lt;00:00, 20.5MB/s]"
          }
        },
        "6da50e3584d0415dbc716661426da28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf5cba43a9d478ba9fe403a3698fa49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f6d162cd99406b98e135e046109510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92aaa368a7c6460d80ccb125adb52a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7030b13506164961ac7c650e4e932e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a9f98b3ff284073ad7544d08df80ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa8c2986caa4b75bda3be9798bfa7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8f2ddf40254eb6ae97898505b5a191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_728a53eaf1b64a59969fb2364d2945cb",
              "IPY_MODEL_e80a608332d64cc9b12305ac883b6572",
              "IPY_MODEL_a713ea558a8049cb850033da7fa59f03"
            ],
            "layout": "IPY_MODEL_075efb493f8b449392bad6f3c31cacc2"
          }
        },
        "728a53eaf1b64a59969fb2364d2945cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31bd7c91e20f4467b99e576550d69d32",
            "placeholder": "​",
            "style": "IPY_MODEL_09c4caaa169041878de46766664c9919",
            "value": "model.safetensors: 100%"
          }
        },
        "e80a608332d64cc9b12305ac883b6572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6b9684f1c34e398df5f8e3a968fedf",
            "max": 56053558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19778a2211614ee7a903526ec98f4c15",
            "value": 56053558
          }
        },
        "a713ea558a8049cb850033da7fa59f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4d62bf85f24690b71863c30e6b0a06",
            "placeholder": "​",
            "style": "IPY_MODEL_88d4922556b14e6e88ba5f05db8cb0e1",
            "value": " 56.1M/56.1M [00:01&lt;00:00, 53.5MB/s]"
          }
        },
        "075efb493f8b449392bad6f3c31cacc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bd7c91e20f4467b99e576550d69d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c4caaa169041878de46766664c9919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb6b9684f1c34e398df5f8e3a968fedf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19778a2211614ee7a903526ec98f4c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b4d62bf85f24690b71863c30e6b0a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d4922556b14e6e88ba5f05db8cb0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15d2e2390c99425a9615bade3692527d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3074692518e049c78877ce1488e39227",
              "IPY_MODEL_685c9342162248f4a32283b3b7e82a6d",
              "IPY_MODEL_47075e85468043168770da6058732cdd"
            ],
            "layout": "IPY_MODEL_d035b1e96f94443ca0ee58d7fee0bd66"
          }
        },
        "3074692518e049c78877ce1488e39227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f25e4326464b1b9d5b72fb55d28b42",
            "placeholder": "​",
            "style": "IPY_MODEL_92bbd10fdc164dd9be810b4c1574ab19",
            "value": "model.safetensors: 100%"
          }
        },
        "685c9342162248f4a32283b3b7e82a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f066940c054fb68e4907f30d09b62c",
            "max": 181012852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4808ebb3464743e5b28e00d7156b050b",
            "value": 181012852
          }
        },
        "47075e85468043168770da6058732cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfae24a131e74a44b727e3bc754841f6",
            "placeholder": "​",
            "style": "IPY_MODEL_1816939eaf07436e8591390c59c3938b",
            "value": " 181M/181M [00:02&lt;00:00, 91.1MB/s]"
          }
        },
        "d035b1e96f94443ca0ee58d7fee0bd66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f25e4326464b1b9d5b72fb55d28b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92bbd10fdc164dd9be810b4c1574ab19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93f066940c054fb68e4907f30d09b62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4808ebb3464743e5b28e00d7156b050b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfae24a131e74a44b727e3bc754841f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1816939eaf07436e8591390c59c3938b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9c590d960e5410583a3e675d78377b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f64185328f7430ca8d8644e2352b3f5",
              "IPY_MODEL_c31fff516a904578ab770c1950c6797a",
              "IPY_MODEL_a85a0b7ee53e412b9300895a008dd7ce"
            ],
            "layout": "IPY_MODEL_3338e4a4f1fe40ef9ab421e13b135b78"
          }
        },
        "1f64185328f7430ca8d8644e2352b3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb353044faa5493ba0b5e3f067a1b68f",
            "placeholder": "​",
            "style": "IPY_MODEL_5650baa1971c4af5a37d668a81a1c995",
            "value": "model.safetensors: 100%"
          }
        },
        "c31fff516a904578ab770c1950c6797a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8ba71ea8624b8bb2d9f59a2081df9a",
            "max": 250309250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71b19832eca14135a664057a799b6512",
            "value": 250309250
          }
        },
        "a85a0b7ee53e412b9300895a008dd7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed740848d58f4c96beedf4b65230f716",
            "placeholder": "​",
            "style": "IPY_MODEL_8a6f2a282141422c8119ea606ca45514",
            "value": " 250M/250M [00:03&lt;00:00, 132MB/s]"
          }
        },
        "3338e4a4f1fe40ef9ab421e13b135b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb353044faa5493ba0b5e3f067a1b68f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5650baa1971c4af5a37d668a81a1c995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd8ba71ea8624b8bb2d9f59a2081df9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b19832eca14135a664057a799b6512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed740848d58f4c96beedf4b65230f716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6f2a282141422c8119ea606ca45514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ad3242a5a54175a17e09f6b78d6d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dde73568768d4395b852a30600526b84",
              "IPY_MODEL_43221b2bc1e445dfabaa20ea16af1f6f",
              "IPY_MODEL_a74c801b6431434ab462e0023566ec46"
            ],
            "layout": "IPY_MODEL_6c3280db53774e76bd0b1d14df929ad7"
          }
        },
        "dde73568768d4395b852a30600526b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb0e869483d42dd8b89b207bb14d8f9",
            "placeholder": "​",
            "style": "IPY_MODEL_45b95f8d422f4f8fa321652993984f17",
            "value": "model.safetensors: 100%"
          }
        },
        "43221b2bc1e445dfabaa20ea16af1f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6572f5edd2154a33b10511639b23cd81",
            "max": 327931912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6918d56c3c84d7fbf8c4e5dfb0624a2",
            "value": 327931912
          }
        },
        "a74c801b6431434ab462e0023566ec46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bbbb414514f40598fb3083cb00bff5b",
            "placeholder": "​",
            "style": "IPY_MODEL_bd9facbe6bbb4fe7a67b1abbf782e3c4",
            "value": " 328M/328M [00:02&lt;00:00, 237MB/s]"
          }
        },
        "6c3280db53774e76bd0b1d14df929ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb0e869483d42dd8b89b207bb14d8f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b95f8d422f4f8fa321652993984f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6572f5edd2154a33b10511639b23cd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6918d56c3c84d7fbf8c4e5dfb0624a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bbbb414514f40598fb3083cb00bff5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd9facbe6bbb4fe7a67b1abbf782e3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Backbone scale ablation (PVTv2 family)\n",
        "\n",
        "PVTv2-B0\n",
        "\n",
        "PVTv2-B1\n",
        "\n",
        "PVTv2-B3\n",
        "\n",
        "PVTv2-B4\n",
        "\n",
        "(optional) PVTv2-B5"
      ],
      "metadata": {
        "id": "4rjtg7YlPM8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PVTv2-B0**"
      ],
      "metadata": {
        "id": "As5e_81rurTO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "ec97742fe3cb4f318f979d6adde89749",
            "cf632fc6b0ca4cf9b60a681ac29f8bf6",
            "d9140c703f0e40008a97c4a0bc621909",
            "36b8633a364f4fcb8cb1a5c4c5e2cff1",
            "6da50e3584d0415dbc716661426da28e",
            "adf5cba43a9d478ba9fe403a3698fa49",
            "62f6d162cd99406b98e135e046109510",
            "92aaa368a7c6460d80ccb125adb52a23",
            "7030b13506164961ac7c650e4e932e4b",
            "8a9f98b3ff284073ad7544d08df80ba9",
            "0aa8c2986caa4b75bda3be9798bfa7ef"
          ]
        },
        "id": "nv1LisTPPMXb",
        "outputId": "79bb4766-5364-49bf-95b4-c53a9e2f390f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets via kagglehub...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Initializing global model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/14.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec97742fe3cb4f318f979d6adde89749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TRUE FL for 12 rounds with backbone=pvt_v2_b0 ...\n",
            "Done training. Best federated VAL accuracy=0.9700 at round 10\n",
            "\n",
            "FINAL OUTPUT (VAL/TEST metrics only):\n",
            "                           setting split           dataset       acc  \\\n",
            "0  Enhanced FELCM (Best θ ds1/ds2)   VAL  ds1+ds2 weighted  0.909953   \n",
            "1      Enhanced FELCM (Best θ ds1)  TEST               ds1  0.898230   \n",
            "2      Enhanced FELCM (Best θ ds2)  TEST               ds2  0.923223   \n",
            "3          Enhanced FELCM (Best θ)  TEST   global weighted  0.918813   \n",
            "\n",
            "   precision_macro  recall_macro  f1_macro  log_loss   loss_ce  \\\n",
            "0         0.761724      0.938551  0.759451  0.277318  0.270269   \n",
            "1         0.902717      0.898933  0.896712  0.380071  0.379986   \n",
            "2         0.918617      0.917311  0.916350  0.271831  0.275057   \n",
            "3         0.915812      0.914069  0.912885  0.290927  0.293569   \n",
            "\n",
            "   auc_roc_macro_ovr  \n",
            "0                NaN  \n",
            "1           0.981358  \n",
            "2           0.985628  \n",
            "3           0.984875  \n",
            "✅ Saved checkpoint: /content/outputs/FL_GAFELCM_PVTv2B0_FUSION_checkpoint.pth\n",
            "✅ Saved VAL/TEST-only CSV: /content/outputs/VAL_TEST_METRICS_ONLY.csv\n"
          ]
        }
      ],
      "source": [
        "import os, time, math, random, sys, subprocess, hashlib\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TRUE FL + GA-FELCM + PVTv2-B0 (FUSION) — 6 Clients (3+3)\n",
        "# Preprocessing ON + Augmentation ON + Fusion ON\n",
        "# CHANGES REQUESTED:\n",
        "#  - backbone -> PVTv2-B0\n",
        "#  - rounds -> 12\n",
        "#  - output -> only VAL/TEST metrics\n",
        "# Saves:\n",
        "#  - checkpoint\n",
        "#  - one CSV with only VAL/TEST metrics\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,  # requested\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"FL_GAFELCM_PVTv2B0_FUSION_checkpoint.pth\")\n",
        "CSV_PATH = os.path.join(OUTDIR, \"VAL_TEST_METRICS_ONLY.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"notumor\" in s or \"no tumor\" in s or \"no_tumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "print(\"Downloading datasets via kagglehub...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not locate required dataset roots\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if not idxs:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        counts[np.argmax(props)] += len(idxs) - counts.sum()\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start : start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_test_splits = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        client_test_splits.append((ds_name, k, base_gid + k, split[k].tolist()))\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])), transforms.ToTensor()])\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        return x, int(row[\"y\"]), row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=(shuffle and sampler is None), sampler=sampler,\n",
        "                      num_workers=CFG[\"num_workers\"], pin_memory=(DEVICE.type == \"cuda\"), drop_last=False,\n",
        "                      persistent_workers=(CFG[\"num_workers\"] > 0))\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(class_weights[ys]), num_samples=len(ys), replacement=True)\n",
        "\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, _, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(src, tune_idx if tune_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(src, val_idx if val_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, _, gid, test_idx in client_test_splits:\n",
        "    src = test1 if ds_name == \"ds1\" else test2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    client_test_loaders.append((ds_name, gid, make_loader(src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, source_id=source_id, client_id=gid)))\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * (lap / (blur + eps)))\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(x2.shape[1]):\n",
        "                xc = x2[:, c:c+1]\n",
        "                xs = F.conv2d(F.pad(xc, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(xc * (1 - self.sharpen) + xs * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        return ((x2 - mn) / (mx - mn + eps)).clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(nn.Conv2d(c, out_dim, 1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU()) for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(nn.Conv2d(out_dim, out_dim, 3, padding=1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU())\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(nn.Linear(dim, max(8, dim // 4)), nn.ReLU(inplace=True), nn.Linear(max(8, dim // 4), dim), nn.Sigmoid())\n",
        "        self.refine = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim, dim))\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "BACKBONE_NAME = \"pvt_v2_b0\"  # requested\n",
        "\n",
        "\n",
        "class PVTv2B0_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(BACKBONE_NAME, pretrained=pretrained, features_only=True, out_indices=(0, 1, 2, 3))\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim), nn.Dropout(head_dropout), nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(), nn.Dropout(head_dropout * 0.5), nn.Linear(max(64, out_dim // 2), num_classes)\n",
        "        )\n",
        "        self.theta_mlp = nn.Sequential(nn.Linear(7, cond_dim), nn.GELU(), nn.Linear(cond_dim, cond_dim))\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "        f0, f1 = self.fuser(feats0), self.fuser(feats1)\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "        t0, t1, t_mid = self.tuner(f0), self.tuner(f1), self.tuner(f_mid)\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        (bb_params if n.startswith(\"backbone.\") else head_params).append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma, preproc_module.alpha, preproc_module.beta, preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0, preproc_module.sharpen, preproc_module.denoise\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if not all_y:\n",
        "        return {k: np.nan for k in [\"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\"]}\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "    out = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    losses = []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        losses.append(float(loss.item()))\n",
        "\n",
        "    return float(np.mean(losses))\n",
        "\n",
        "\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    sep = 0.0\n",
        "    if len(classes) >= 2:\n",
        "        centroids, vars_, sizes = [], [], []\n",
        "        for c in classes:\n",
        "            e = emb[y == c]\n",
        "            if e.size(0) < 2:\n",
        "                continue\n",
        "            mu = e.mean(dim=0)\n",
        "            centroids.append(mu)\n",
        "            vars_.append((e - mu).pow(2).sum(dim=1).mean().item())\n",
        "            sizes.append(e.size(0))\n",
        "        if len(centroids) >= 2:\n",
        "            centroids = torch.stack(centroids, dim=0)\n",
        "            gm = centroids.mean(dim=0)\n",
        "            between = sum(n * (c - gm).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "            within = float(np.mean(vars_)) if vars_ else 1e-6\n",
        "            sep = float(between / (within + 1e-6))\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None, [], 0.0\n",
        "    pop = elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)]\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "    bx, by = bx[: CFG[\"batch_size\"]].contiguous(), by[: CFG[\"batch_size\"]].contiguous()\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "    scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1], [th for _, th in scored[: CFG[\"ga_elites\"]]], float(scored[0][0])\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    total = sum(w for _, _, w in mets)\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    keys = mets[0][1].keys()\n",
        "    return {k: float(np.average([m[1].get(k, np.nan) for m in mets], weights=[m[2] for m in mets])) for k in keys}\n",
        "\n",
        "\n",
        "print(\"Initializing global model...\")\n",
        "global_model = PVTv2B0_MultiScale(NUM_CLASSES, pretrained=True, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "set_trainable_for_round(global_model, 1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values + \\\n",
        "         train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc, best_round_saved = -1.0, None\n",
        "best_model_state = None\n",
        "\n",
        "print(f\"Training TRUE FL for {CFG['rounds']} rounds with backbone={BACKBONE_NAME} ...\")\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "        else:\n",
        "            best_theta = None\n",
        "            pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = PVTv2B0_MultiScale(NUM_CLASSES, pretrained=False, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "        set_trainable_for_round(local_model, rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        sched = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=sched, scaler=scaler)\n",
        "\n",
        "        met = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_rows.append({\"val_acc\": met.get(\"acc\", np.nan), \"val_size\": len(val_loader.dataset)})\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    fedavg_update(global_model, local_models, [w / wsum for w in local_weights], [n for n, p in local_models[0].named_parameters() if p.requires_grad])\n",
        "\n",
        "    lv = pd.DataFrame(local_rows)\n",
        "    round_acc = float(np.average(lv[\"val_acc\"], weights=lv[\"val_size\"])) if lv[\"val_size\"].sum() > 0 else np.nan\n",
        "    if np.isfinite(round_acc) and round_acc > best_global_acc:\n",
        "        best_global_acc = round_acc\n",
        "        best_round_saved = rnd\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "print(f\"Done training. Best federated VAL accuracy={best_global_acc:.4f} at round {best_round_saved}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# Re-run GA with the restored best global model so final VAL/TEST uses GA-FELCM (not Identity preproc)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "best_theta_by_client = {}\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, tune_loader, _ = client_loaders[k]\n",
        "    ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "    elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "    th, _, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "    best_theta_by_client[k] = th\n",
        "\n",
        "\n",
        "def preproc_for_client(client_id: int):\n",
        "    th = best_theta_by_client.get(client_id)\n",
        "    return theta_to_module(th).to(DEVICE) if th is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = preproc_for_client(k)\n",
        "    met = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = preproc_for_client(gid)\n",
        "        met = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((gid, met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets) if mets else {}\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([\n",
        "    (0, test_ds1, len(test1)),\n",
        "    (1, test_ds2, len(test2)),\n",
        "])\n",
        "\n",
        "\n",
        "def compact_metrics(m):\n",
        "    keep = [\"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\", \"loss_ce\", \"auc_roc_macro_ovr\"]\n",
        "    return {k: float(m[k]) for k in keep if k in m}\n",
        "\n",
        "\n",
        "val_test_df = pd.DataFrame([\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **compact_metrics(val_best)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **compact_metrics(test_ds1)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **compact_metrics(test_ds2)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **compact_metrics(global_test)},\n",
        "])\n",
        "\n",
        "print(\"\\nFINAL OUTPUT (VAL/TEST metrics only):\")\n",
        "print(val_test_df)\n",
        "\n",
        "checkpoint = {\n",
        "    \"state_dict\": {k: v.detach().cpu() for k, v in global_model.state_dict().items()},\n",
        "    \"config\": CFG,\n",
        "    \"seed\": SEED,\n",
        "    \"device_used\": str(DEVICE),\n",
        "    \"dataset1_raw_root\": DS1_ROOT,\n",
        "    \"dataset2_root\": DS2_ROOT,\n",
        "    \"labels\": labels,\n",
        "    \"label2id\": label2id,\n",
        "    \"id2label\": id2label,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"backbone_name\": BACKBONE_NAME,\n",
        "    \"best_round_saved\": best_round_saved,\n",
        "    \"best_val_acc\": best_global_acc,\n",
        "    \"final_val_federated\": val_best,\n",
        "    \"final_test_ds1\": test_ds1,\n",
        "    \"final_test_ds2\": test_ds2,\n",
        "    \"final_test_global_weighted\": global_test,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)\n",
        "val_test_df.to_csv(CSV_PATH, index=False)\n",
        "print(f\"✅ Saved checkpoint: {MODEL_PATH}\")\n",
        "print(f\"✅ Saved VAL/TEST-only CSV: {CSV_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PVTv2-B1**\n",
        "\n"
      ],
      "metadata": {
        "id": "XBKq892duuLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess, hashlib\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TRUE FL + GA-FELCM + PVTv2-B1 (FUSION) — 6 Clients (3+3)\n",
        "# Preprocessing ON + Augmentation ON + Fusion ON\n",
        "# CHANGES REQUESTED:\n",
        "#  - backbone -> PVTv2-B1\n",
        "#  - rounds -> 12\n",
        "#  - output -> only VAL/TEST metrics\n",
        "# Saves:\n",
        "#  - checkpoint\n",
        "#  - one CSV with only VAL/TEST metrics\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,  # requested\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"FL_GAFELCM_PVTv2B1_FUSION_checkpoint.pth\")\n",
        "CSV_PATH = os.path.join(OUTDIR, \"VAL_TEST_METRICS_ONLY.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"notumor\" in s or \"no tumor\" in s or \"no_tumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "print(\"Downloading datasets via kagglehub...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not locate required dataset roots\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if not idxs:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        counts[np.argmax(props)] += len(idxs) - counts.sum()\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start : start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_test_splits = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        client_test_splits.append((ds_name, k, base_gid + k, split[k].tolist()))\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])), transforms.ToTensor()])\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        return x, int(row[\"y\"]), row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=(shuffle and sampler is None), sampler=sampler,\n",
        "                      num_workers=CFG[\"num_workers\"], pin_memory=(DEVICE.type == \"cuda\"), drop_last=False,\n",
        "                      persistent_workers=(CFG[\"num_workers\"] > 0))\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(class_weights[ys]), num_samples=len(ys), replacement=True)\n",
        "\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, _, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(src, tune_idx if tune_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(src, val_idx if val_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, _, gid, test_idx in client_test_splits:\n",
        "    src = test1 if ds_name == \"ds1\" else test2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    client_test_loaders.append((ds_name, gid, make_loader(src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, source_id=source_id, client_id=gid)))\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * (lap / (blur + eps)))\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(x2.shape[1]):\n",
        "                xc = x2[:, c:c+1]\n",
        "                xs = F.conv2d(F.pad(xc, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(xc * (1 - self.sharpen) + xs * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        return ((x2 - mn) / (mx - mn + eps)).clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(nn.Conv2d(c, out_dim, 1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU()) for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(nn.Conv2d(out_dim, out_dim, 3, padding=1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU())\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(nn.Linear(dim, max(8, dim // 4)), nn.ReLU(inplace=True), nn.Linear(max(8, dim // 4), dim), nn.Sigmoid())\n",
        "        self.refine = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim, dim))\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "BACKBONE_NAME = \"pvt_v2_b1\"  # requested\n",
        "\n",
        "\n",
        "class PVTv2B1_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(BACKBONE_NAME, pretrained=pretrained, features_only=True, out_indices=(0, 1, 2, 3))\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim), nn.Dropout(head_dropout), nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(), nn.Dropout(head_dropout * 0.5), nn.Linear(max(64, out_dim // 2), num_classes)\n",
        "        )\n",
        "        self.theta_mlp = nn.Sequential(nn.Linear(7, cond_dim), nn.GELU(), nn.Linear(cond_dim, cond_dim))\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "        f0, f1 = self.fuser(feats0), self.fuser(feats1)\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "        t0, t1, t_mid = self.tuner(f0), self.tuner(f1), self.tuner(f_mid)\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        (bb_params if n.startswith(\"backbone.\") else head_params).append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma, preproc_module.alpha, preproc_module.beta, preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0, preproc_module.sharpen, preproc_module.denoise\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if not all_y:\n",
        "        return {k: np.nan for k in [\"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\"]}\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "    out = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    losses = []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        losses.append(float(loss.item()))\n",
        "\n",
        "    return float(np.mean(losses))\n",
        "\n",
        "\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    sep = 0.0\n",
        "    if len(classes) >= 2:\n",
        "        centroids, vars_, sizes = [], [], []\n",
        "        for c in classes:\n",
        "            e = emb[y == c]\n",
        "            if e.size(0) < 2:\n",
        "                continue\n",
        "            mu = e.mean(dim=0)\n",
        "            centroids.append(mu)\n",
        "            vars_.append((e - mu).pow(2).sum(dim=1).mean().item())\n",
        "            sizes.append(e.size(0))\n",
        "        if len(centroids) >= 2:\n",
        "            centroids = torch.stack(centroids, dim=0)\n",
        "            gm = centroids.mean(dim=0)\n",
        "            between = sum(n * (c - gm).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "            within = float(np.mean(vars_)) if vars_ else 1e-6\n",
        "            sep = float(between / (within + 1e-6))\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None, [], 0.0\n",
        "    pop = elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)]\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "    bx, by = bx[: CFG[\"batch_size\"]].contiguous(), by[: CFG[\"batch_size\"]].contiguous()\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "    scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1], [th for _, th in scored[: CFG[\"ga_elites\"]]], float(scored[0][0])\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    total = sum(w for _, _, w in mets)\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    keys = mets[0][1].keys()\n",
        "    return {k: float(np.average([m[1].get(k, np.nan) for m in mets], weights=[m[2] for m in mets])) for k in keys}\n",
        "\n",
        "\n",
        "print(\"Initializing global model...\")\n",
        "global_model = PVTv2B1_MultiScale(NUM_CLASSES, pretrained=True, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "set_trainable_for_round(global_model, 1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values + \\\n",
        "         train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc, best_round_saved = -1.0, None\n",
        "best_model_state = None\n",
        "\n",
        "print(f\"Training TRUE FL for {CFG['rounds']} rounds with backbone={BACKBONE_NAME} ...\")\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "        else:\n",
        "            best_theta = None\n",
        "            pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = PVTv2B1_MultiScale(NUM_CLASSES, pretrained=False, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "        set_trainable_for_round(local_model, rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        sched = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=sched, scaler=scaler)\n",
        "\n",
        "        met = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_rows.append({\"val_acc\": met.get(\"acc\", np.nan), \"val_size\": len(val_loader.dataset)})\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    fedavg_update(global_model, local_models, [w / wsum for w in local_weights], [n for n, p in local_models[0].named_parameters() if p.requires_grad])\n",
        "\n",
        "    lv = pd.DataFrame(local_rows)\n",
        "    round_acc = float(np.average(lv[\"val_acc\"], weights=lv[\"val_size\"])) if lv[\"val_size\"].sum() > 0 else np.nan\n",
        "    if np.isfinite(round_acc) and round_acc > best_global_acc:\n",
        "        best_global_acc = round_acc\n",
        "        best_round_saved = rnd\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "print(f\"Done training. Best federated VAL accuracy={best_global_acc:.4f} at round {best_round_saved}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# Re-run GA with the restored best global model so final VAL/TEST uses GA-FELCM (not Identity preproc)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "best_theta_by_client = {}\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, tune_loader, _ = client_loaders[k]\n",
        "    ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "    elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "    th, _, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "    best_theta_by_client[k] = th\n",
        "\n",
        "\n",
        "def preproc_for_client(client_id: int):\n",
        "    th = best_theta_by_client.get(client_id)\n",
        "    return theta_to_module(th).to(DEVICE) if th is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = preproc_for_client(k)\n",
        "    met = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = preproc_for_client(gid)\n",
        "        met = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((gid, met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets) if mets else {}\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([\n",
        "    (0, test_ds1, len(test1)),\n",
        "    (1, test_ds2, len(test2)),\n",
        "])\n",
        "\n",
        "\n",
        "def compact_metrics(m):\n",
        "    keep = [\"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\", \"loss_ce\", \"auc_roc_macro_ovr\"]\n",
        "    return {k: float(m[k]) for k in keep if k in m}\n",
        "\n",
        "\n",
        "val_test_df = pd.DataFrame([\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **compact_metrics(val_best)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **compact_metrics(test_ds1)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **compact_metrics(test_ds2)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **compact_metrics(global_test)},\n",
        "])\n",
        "\n",
        "print(\"\\nFINAL OUTPUT (VAL/TEST metrics only):\")\n",
        "print(val_test_df)\n",
        "\n",
        "checkpoint = {\n",
        "    \"state_dict\": {k: v.detach().cpu() for k, v in global_model.state_dict().items()},\n",
        "    \"config\": CFG,\n",
        "    \"seed\": SEED,\n",
        "    \"device_used\": str(DEVICE),\n",
        "    \"dataset1_raw_root\": DS1_ROOT,\n",
        "    \"dataset2_root\": DS2_ROOT,\n",
        "    \"labels\": labels,\n",
        "    \"label2id\": label2id,\n",
        "    \"id2label\": id2label,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"backbone_name\": BACKBONE_NAME,\n",
        "    \"best_round_saved\": best_round_saved,\n",
        "    \"best_val_acc\": best_global_acc,\n",
        "    \"final_val_federated\": val_best,\n",
        "    \"final_test_ds1\": test_ds1,\n",
        "    \"final_test_ds2\": test_ds2,\n",
        "    \"final_test_global_weighted\": global_test,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)\n",
        "val_test_df.to_csv(CSV_PATH, index=False)\n",
        "print(f\"✅ Saved checkpoint: {MODEL_PATH}\")\n",
        "print(f\"✅ Saved VAL/TEST-only CSV: {CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "cf8f2ddf40254eb6ae97898505b5a191",
            "728a53eaf1b64a59969fb2364d2945cb",
            "e80a608332d64cc9b12305ac883b6572",
            "a713ea558a8049cb850033da7fa59f03",
            "075efb493f8b449392bad6f3c31cacc2",
            "31bd7c91e20f4467b99e576550d69d32",
            "09c4caaa169041878de46766664c9919",
            "bb6b9684f1c34e398df5f8e3a968fedf",
            "19778a2211614ee7a903526ec98f4c15",
            "5b4d62bf85f24690b71863c30e6b0a06",
            "88d4922556b14e6e88ba5f05db8cb0e1"
          ]
        },
        "id": "bRKHWTT8uvKF",
        "outputId": "d944b11d-57e9-478e-ef08-d799d58fc747"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets via kagglehub...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Initializing global model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/56.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf8f2ddf40254eb6ae97898505b5a191"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TRUE FL for 12 rounds with backbone=pvt_v2_b1 ...\n",
            "Done training. Best federated VAL accuracy=0.9779 at round 10\n",
            "\n",
            "FINAL OUTPUT (VAL/TEST metrics only):\n",
            "                           setting split           dataset       acc  \\\n",
            "0  Enhanced FELCM (Best θ ds1/ds2)   VAL  ds1+ds2 weighted  0.960506   \n",
            "1      Enhanced FELCM (Best θ ds1)  TEST               ds1  0.942478   \n",
            "2      Enhanced FELCM (Best θ ds2)  TEST               ds2  0.936493   \n",
            "3          Enhanced FELCM (Best θ)  TEST   global weighted  0.937549   \n",
            "\n",
            "   precision_macro  recall_macro  f1_macro  log_loss   loss_ce  \\\n",
            "0         0.826924      0.956931  0.853176  0.168795  0.163554   \n",
            "1         0.944453      0.944455  0.942591  0.222971  0.215454   \n",
            "2         0.934290      0.936575  0.931809  0.225085  0.225703   \n",
            "3         0.936083      0.937965  0.933711  0.224712  0.223895   \n",
            "\n",
            "   auc_roc_macro_ovr  \n",
            "0                NaN  \n",
            "1           0.985592  \n",
            "2           0.993379  \n",
            "3           0.992005  \n",
            "✅ Saved checkpoint: /content/outputs/FL_GAFELCM_PVTv2B1_FUSION_checkpoint.pth\n",
            "✅ Saved VAL/TEST-only CSV: /content/outputs/VAL_TEST_METRICS_ONLY.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PVTv2-B3**\n",
        "\n"
      ],
      "metadata": {
        "id": "SX_NtLegzGJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess, hashlib\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TRUE FL + GA-FELCM + PVTv2-B3 (FUSION) — 6 Clients (3+3)\n",
        "# Preprocessing ON + Augmentation ON + Fusion ON\n",
        "# CHANGES REQUESTED:\n",
        "#  - backbone -> PVTv2-B3\n",
        "#  - rounds -> 12\n",
        "#  - output -> only VAL/TEST metrics\n",
        "# Saves:\n",
        "#  - checkpoint\n",
        "#  - one CSV with only VAL/TEST metrics\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,  # requested\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"FL_GAFELCM_PVTv2B3_FUSION_checkpoint.pth\")\n",
        "CSV_PATH = os.path.join(OUTDIR, \"VAL_TEST_METRICS_ONLY.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"notumor\" in s or \"no tumor\" in s or \"no_tumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "print(\"Downloading datasets via kagglehub...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not locate required dataset roots\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if not idxs:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        counts[np.argmax(props)] += len(idxs) - counts.sum()\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start : start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_test_splits = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        client_test_splits.append((ds_name, k, base_gid + k, split[k].tolist()))\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])), transforms.ToTensor()])\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        return x, int(row[\"y\"]), row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=(shuffle and sampler is None), sampler=sampler,\n",
        "                      num_workers=CFG[\"num_workers\"], pin_memory=(DEVICE.type == \"cuda\"), drop_last=False,\n",
        "                      persistent_workers=(CFG[\"num_workers\"] > 0))\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(class_weights[ys]), num_samples=len(ys), replacement=True)\n",
        "\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, _, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(src, tune_idx if tune_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(src, val_idx if val_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, _, gid, test_idx in client_test_splits:\n",
        "    src = test1 if ds_name == \"ds1\" else test2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    client_test_loaders.append((ds_name, gid, make_loader(src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, source_id=source_id, client_id=gid)))\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * (lap / (blur + eps)))\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(x2.shape[1]):\n",
        "                xc = x2[:, c:c+1]\n",
        "                xs = F.conv2d(F.pad(xc, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(xc * (1 - self.sharpen) + xs * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        return ((x2 - mn) / (mx - mn + eps)).clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(nn.Conv2d(c, out_dim, 1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU()) for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(nn.Conv2d(out_dim, out_dim, 3, padding=1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU())\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(nn.Linear(dim, max(8, dim // 4)), nn.ReLU(inplace=True), nn.Linear(max(8, dim // 4), dim), nn.Sigmoid())\n",
        "        self.refine = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim, dim))\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "BACKBONE_NAME = \"pvt_v2_b3\"  # requested\n",
        "\n",
        "\n",
        "class PVTv2B3_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(BACKBONE_NAME, pretrained=pretrained, features_only=True, out_indices=(0, 1, 2, 3))\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim), nn.Dropout(head_dropout), nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(), nn.Dropout(head_dropout * 0.5), nn.Linear(max(64, out_dim // 2), num_classes)\n",
        "        )\n",
        "        self.theta_mlp = nn.Sequential(nn.Linear(7, cond_dim), nn.GELU(), nn.Linear(cond_dim, cond_dim))\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "        f0, f1 = self.fuser(feats0), self.fuser(feats1)\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "        t0, t1, t_mid = self.tuner(f0), self.tuner(f1), self.tuner(f_mid)\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        (bb_params if n.startswith(\"backbone.\") else head_params).append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma, preproc_module.alpha, preproc_module.beta, preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0, preproc_module.sharpen, preproc_module.denoise\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if not all_y:\n",
        "        return {k: np.nan for k in [\"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\"]}\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "    out = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    losses = []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        losses.append(float(loss.item()))\n",
        "\n",
        "    return float(np.mean(losses))\n",
        "\n",
        "\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    sep = 0.0\n",
        "    if len(classes) >= 2:\n",
        "        centroids, vars_, sizes = [], [], []\n",
        "        for c in classes:\n",
        "            e = emb[y == c]\n",
        "            if e.size(0) < 2:\n",
        "                continue\n",
        "            mu = e.mean(dim=0)\n",
        "            centroids.append(mu)\n",
        "            vars_.append((e - mu).pow(2).sum(dim=1).mean().item())\n",
        "            sizes.append(e.size(0))\n",
        "        if len(centroids) >= 2:\n",
        "            centroids = torch.stack(centroids, dim=0)\n",
        "            gm = centroids.mean(dim=0)\n",
        "            between = sum(n * (c - gm).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "            within = float(np.mean(vars_)) if vars_ else 1e-6\n",
        "            sep = float(between / (within + 1e-6))\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None, [], 0.0\n",
        "    pop = elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)]\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "    bx, by = bx[: CFG[\"batch_size\"]].contiguous(), by[: CFG[\"batch_size\"]].contiguous()\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "    scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1], [th for _, th in scored[: CFG[\"ga_elites\"]]], float(scored[0][0])\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    total = sum(w for _, _, w in mets)\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    keys = mets[0][1].keys()\n",
        "    return {k: float(np.average([m[1].get(k, np.nan) for m in mets], weights=[m[2] for m in mets])) for k in keys}\n",
        "\n",
        "\n",
        "print(\"Initializing global model...\")\n",
        "global_model = PVTv2B3_MultiScale(NUM_CLASSES, pretrained=True, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "set_trainable_for_round(global_model, 1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values + \\\n",
        "         train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc, best_round_saved = -1.0, None\n",
        "best_model_state = None\n",
        "\n",
        "print(f\"Training TRUE FL for {CFG['rounds']} rounds with backbone={BACKBONE_NAME} ...\")\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "        else:\n",
        "            best_theta = None\n",
        "            pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = PVTv2B3_MultiScale(NUM_CLASSES, pretrained=False, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "        set_trainable_for_round(local_model, rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        sched = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=sched, scaler=scaler)\n",
        "\n",
        "        met = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_rows.append({\"val_acc\": met.get(\"acc\", np.nan), \"val_size\": len(val_loader.dataset)})\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    fedavg_update(global_model, local_models, [w / wsum for w in local_weights], [n for n, p in local_models[0].named_parameters() if p.requires_grad])\n",
        "\n",
        "    lv = pd.DataFrame(local_rows)\n",
        "    round_acc = float(np.average(lv[\"val_acc\"], weights=lv[\"val_size\"])) if lv[\"val_size\"].sum() > 0 else np.nan\n",
        "    if np.isfinite(round_acc) and round_acc > best_global_acc:\n",
        "        best_global_acc = round_acc\n",
        "        best_round_saved = rnd\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "print(f\"Done training. Best federated VAL accuracy={best_global_acc:.4f} at round {best_round_saved}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# Re-run GA with the restored best global model so final VAL/TEST uses GA-FELCM (not Identity preproc)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "best_theta_by_client = {}\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, tune_loader, _ = client_loaders[k]\n",
        "    ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "    elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "    th, _, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "    best_theta_by_client[k] = th\n",
        "\n",
        "\n",
        "def preproc_for_client(client_id: int):\n",
        "    th = best_theta_by_client.get(client_id)\n",
        "    return theta_to_module(th).to(DEVICE) if th is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = preproc_for_client(k)\n",
        "    met = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = preproc_for_client(gid)\n",
        "        met = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((gid, met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets) if mets else {}\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([\n",
        "    (0, test_ds1, len(test1)),\n",
        "    (1, test_ds2, len(test2)),\n",
        "])\n",
        "\n",
        "\n",
        "def compact_metrics(m):\n",
        "    keep = [\"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\", \"loss_ce\", \"auc_roc_macro_ovr\"]\n",
        "    return {k: float(m[k]) for k in keep if k in m}\n",
        "\n",
        "\n",
        "val_test_df = pd.DataFrame([\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **compact_metrics(val_best)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **compact_metrics(test_ds1)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **compact_metrics(test_ds2)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **compact_metrics(global_test)},\n",
        "])\n",
        "\n",
        "print(\"\\nFINAL OUTPUT (VAL/TEST metrics only):\")\n",
        "print(val_test_df)\n",
        "\n",
        "checkpoint = {\n",
        "    \"state_dict\": {k: v.detach().cpu() for k, v in global_model.state_dict().items()},\n",
        "    \"config\": CFG,\n",
        "    \"seed\": SEED,\n",
        "    \"device_used\": str(DEVICE),\n",
        "    \"dataset1_raw_root\": DS1_ROOT,\n",
        "    \"dataset2_root\": DS2_ROOT,\n",
        "    \"labels\": labels,\n",
        "    \"label2id\": label2id,\n",
        "    \"id2label\": id2label,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"backbone_name\": BACKBONE_NAME,\n",
        "    \"best_round_saved\": best_round_saved,\n",
        "    \"best_val_acc\": best_global_acc,\n",
        "    \"final_val_federated\": val_best,\n",
        "    \"final_test_ds1\": test_ds1,\n",
        "    \"final_test_ds2\": test_ds2,\n",
        "    \"final_test_global_weighted\": global_test,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)\n",
        "val_test_df.to_csv(CSV_PATH, index=False)\n",
        "print(f\"✅ Saved checkpoint: {MODEL_PATH}\")\n",
        "print(f\"✅ Saved VAL/TEST-only CSV: {CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623,
          "referenced_widgets": [
            "15d2e2390c99425a9615bade3692527d",
            "3074692518e049c78877ce1488e39227",
            "685c9342162248f4a32283b3b7e82a6d",
            "47075e85468043168770da6058732cdd",
            "d035b1e96f94443ca0ee58d7fee0bd66",
            "96f25e4326464b1b9d5b72fb55d28b42",
            "92bbd10fdc164dd9be810b4c1574ab19",
            "93f066940c054fb68e4907f30d09b62c",
            "4808ebb3464743e5b28e00d7156b050b",
            "cfae24a131e74a44b727e3bc754841f6",
            "1816939eaf07436e8591390c59c3938b"
          ]
        },
        "id": "XkdX-mUJzH8-",
        "outputId": "62976497-269d-4eda-ad8d-840c6478fb22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets via kagglehub...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Initializing global model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/181M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15d2e2390c99425a9615bade3692527d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TRUE FL for 12 rounds with backbone=pvt_v2_b3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done training. Best federated VAL accuracy=0.9842 at round 12\n",
            "\n",
            "FINAL OUTPUT (VAL/TEST metrics only):\n",
            "                           setting split           dataset       acc  \\\n",
            "0  Enhanced FELCM (Best θ ds1/ds2)   VAL  ds1+ds2 weighted  0.946288   \n",
            "1      Enhanced FELCM (Best θ ds1)  TEST               ds1  0.938053   \n",
            "2      Enhanced FELCM (Best θ ds2)  TEST               ds2  0.949763   \n",
            "3          Enhanced FELCM (Best θ)  TEST   global weighted  0.947697   \n",
            "\n",
            "   precision_macro  recall_macro  f1_macro  log_loss   loss_ce  \\\n",
            "0         0.765838      0.943700  0.777604  0.199099  0.194695   \n",
            "1         0.943312      0.933781  0.935748  0.272568  0.270744   \n",
            "2         0.948912      0.945429  0.945884  0.184047  0.185038   \n",
            "3         0.947924      0.943374  0.944096  0.199664  0.200159   \n",
            "\n",
            "   auc_roc_macro_ovr  \n",
            "0                NaN  \n",
            "1           0.983110  \n",
            "2           0.992767  \n",
            "3           0.991063  \n",
            "✅ Saved checkpoint: /content/outputs/FL_GAFELCM_PVTv2B3_FUSION_checkpoint.pth\n",
            "✅ Saved VAL/TEST-only CSV: /content/outputs/VAL_TEST_METRICS_ONLY.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PVTv2-B4**\n",
        "\n"
      ],
      "metadata": {
        "id": "_T16WCHHzIRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess, hashlib\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TRUE FL + GA-FELCM + PVTv2-B4 (FUSION) — 6 Clients (3+3)\n",
        "# Preprocessing ON + Augmentation ON + Fusion ON\n",
        "# CHANGES REQUESTED:\n",
        "#  - backbone -> PVTv2-B4\n",
        "#  - rounds -> 12\n",
        "#  - output -> only VAL/TEST metrics\n",
        "# Saves:\n",
        "#  - checkpoint\n",
        "#  - one CSV with only VAL/TEST metrics\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,  # requested\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"FL_GAFELCM_PVTv2B4_FUSION_checkpoint.pth\")\n",
        "CSV_PATH = os.path.join(OUTDIR, \"VAL_TEST_METRICS_ONLY.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"notumor\" in s or \"no tumor\" in s or \"no_tumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "print(\"Downloading datasets via kagglehub...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not locate required dataset roots\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if not idxs:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        counts[np.argmax(props)] += len(idxs) - counts.sum()\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start : start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_test_splits = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        client_test_splits.append((ds_name, k, base_gid + k, split[k].tolist()))\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])), transforms.ToTensor()])\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        return x, int(row[\"y\"]), row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=(shuffle and sampler is None), sampler=sampler,\n",
        "                      num_workers=CFG[\"num_workers\"], pin_memory=(DEVICE.type == \"cuda\"), drop_last=False,\n",
        "                      persistent_workers=(CFG[\"num_workers\"] > 0))\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(class_weights[ys]), num_samples=len(ys), replacement=True)\n",
        "\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, _, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(src, tune_idx if tune_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(src, val_idx if val_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, _, gid, test_idx in client_test_splits:\n",
        "    src = test1 if ds_name == \"ds1\" else test2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    client_test_loaders.append((ds_name, gid, make_loader(src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, source_id=source_id, client_id=gid)))\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * (lap / (blur + eps)))\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(x2.shape[1]):\n",
        "                xc = x2[:, c:c+1]\n",
        "                xs = F.conv2d(F.pad(xc, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(xc * (1 - self.sharpen) + xs * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        return ((x2 - mn) / (mx - mn + eps)).clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(nn.Conv2d(c, out_dim, 1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU()) for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(nn.Conv2d(out_dim, out_dim, 3, padding=1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU())\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(nn.Linear(dim, max(8, dim // 4)), nn.ReLU(inplace=True), nn.Linear(max(8, dim // 4), dim), nn.Sigmoid())\n",
        "        self.refine = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim, dim))\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "BACKBONE_NAME = \"pvt_v2_b4\"  # requested\n",
        "\n",
        "\n",
        "class PVTv2B4_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(BACKBONE_NAME, pretrained=pretrained, features_only=True, out_indices=(0, 1, 2, 3))\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim), nn.Dropout(head_dropout), nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(), nn.Dropout(head_dropout * 0.5), nn.Linear(max(64, out_dim // 2), num_classes)\n",
        "        )\n",
        "        self.theta_mlp = nn.Sequential(nn.Linear(7, cond_dim), nn.GELU(), nn.Linear(cond_dim, cond_dim))\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "        f0, f1 = self.fuser(feats0), self.fuser(feats1)\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "        t0, t1, t_mid = self.tuner(f0), self.tuner(f1), self.tuner(f_mid)\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        (bb_params if n.startswith(\"backbone.\") else head_params).append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma, preproc_module.alpha, preproc_module.beta, preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0, preproc_module.sharpen, preproc_module.denoise\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if not all_y:\n",
        "        return {k: np.nan for k in [\"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\"]}\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "    out = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    losses = []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        losses.append(float(loss.item()))\n",
        "\n",
        "    return float(np.mean(losses))\n",
        "\n",
        "\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    sep = 0.0\n",
        "    if len(classes) >= 2:\n",
        "        centroids, vars_, sizes = [], [], []\n",
        "        for c in classes:\n",
        "            e = emb[y == c]\n",
        "            if e.size(0) < 2:\n",
        "                continue\n",
        "            mu = e.mean(dim=0)\n",
        "            centroids.append(mu)\n",
        "            vars_.append((e - mu).pow(2).sum(dim=1).mean().item())\n",
        "            sizes.append(e.size(0))\n",
        "        if len(centroids) >= 2:\n",
        "            centroids = torch.stack(centroids, dim=0)\n",
        "            gm = centroids.mean(dim=0)\n",
        "            between = sum(n * (c - gm).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "            within = float(np.mean(vars_)) if vars_ else 1e-6\n",
        "            sep = float(between / (within + 1e-6))\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None, [], 0.0\n",
        "    pop = elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)]\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "    bx, by = bx[: CFG[\"batch_size\"]].contiguous(), by[: CFG[\"batch_size\"]].contiguous()\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "    scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1], [th for _, th in scored[: CFG[\"ga_elites\"]]], float(scored[0][0])\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    total = sum(w for _, _, w in mets)\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    keys = mets[0][1].keys()\n",
        "    return {k: float(np.average([m[1].get(k, np.nan) for m in mets], weights=[m[2] for m in mets])) for k in keys}\n",
        "\n",
        "\n",
        "print(\"Initializing global model...\")\n",
        "global_model = PVTv2B4_MultiScale(NUM_CLASSES, pretrained=True, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "set_trainable_for_round(global_model, 1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values + \\\n",
        "         train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc, best_round_saved = -1.0, None\n",
        "best_model_state = None\n",
        "\n",
        "print(f\"Training TRUE FL for {CFG['rounds']} rounds with backbone={BACKBONE_NAME} ...\")\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "        else:\n",
        "            best_theta = None\n",
        "            pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = PVTv2B4_MultiScale(NUM_CLASSES, pretrained=False, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "        set_trainable_for_round(local_model, rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        sched = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=sched, scaler=scaler)\n",
        "\n",
        "        met = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_rows.append({\"val_acc\": met.get(\"acc\", np.nan), \"val_size\": len(val_loader.dataset)})\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    fedavg_update(global_model, local_models, [w / wsum for w in local_weights], [n for n, p in local_models[0].named_parameters() if p.requires_grad])\n",
        "\n",
        "    lv = pd.DataFrame(local_rows)\n",
        "    round_acc = float(np.average(lv[\"val_acc\"], weights=lv[\"val_size\"])) if lv[\"val_size\"].sum() > 0 else np.nan\n",
        "    if np.isfinite(round_acc) and round_acc > best_global_acc:\n",
        "        best_global_acc = round_acc\n",
        "        best_round_saved = rnd\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "print(f\"Done training. Best federated VAL accuracy={best_global_acc:.4f} at round {best_round_saved}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# Re-run GA with the restored best global model so final VAL/TEST uses GA-FELCM (not Identity preproc)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "best_theta_by_client = {}\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, tune_loader, _ = client_loaders[k]\n",
        "    ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "    elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "    th, _, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "    best_theta_by_client[k] = th\n",
        "\n",
        "\n",
        "def preproc_for_client(client_id: int):\n",
        "    th = best_theta_by_client.get(client_id)\n",
        "    return theta_to_module(th).to(DEVICE) if th is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = preproc_for_client(k)\n",
        "    met = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = preproc_for_client(gid)\n",
        "        met = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((gid, met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets) if mets else {}\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([\n",
        "    (0, test_ds1, len(test1)),\n",
        "    (1, test_ds2, len(test2)),\n",
        "])\n",
        "\n",
        "\n",
        "def compact_metrics(m):\n",
        "    keep = [\"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\", \"loss_ce\", \"auc_roc_macro_ovr\"]\n",
        "    return {k: float(m[k]) for k in keep if k in m}\n",
        "\n",
        "\n",
        "val_test_df = pd.DataFrame([\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **compact_metrics(val_best)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **compact_metrics(test_ds1)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **compact_metrics(test_ds2)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **compact_metrics(global_test)},\n",
        "])\n",
        "\n",
        "print(\"\\nFINAL OUTPUT (VAL/TEST metrics only):\")\n",
        "print(val_test_df)\n",
        "\n",
        "checkpoint = {\n",
        "    \"state_dict\": {k: v.detach().cpu() for k, v in global_model.state_dict().items()},\n",
        "    \"config\": CFG,\n",
        "    \"seed\": SEED,\n",
        "    \"device_used\": str(DEVICE),\n",
        "    \"dataset1_raw_root\": DS1_ROOT,\n",
        "    \"dataset2_root\": DS2_ROOT,\n",
        "    \"labels\": labels,\n",
        "    \"label2id\": label2id,\n",
        "    \"id2label\": id2label,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"backbone_name\": BACKBONE_NAME,\n",
        "    \"best_round_saved\": best_round_saved,\n",
        "    \"best_val_acc\": best_global_acc,\n",
        "    \"final_val_federated\": val_best,\n",
        "    \"final_test_ds1\": test_ds1,\n",
        "    \"final_test_ds2\": test_ds2,\n",
        "    \"final_test_global_weighted\": global_test,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)\n",
        "val_test_df.to_csv(CSV_PATH, index=False)\n",
        "print(f\"✅ Saved checkpoint: {MODEL_PATH}\")\n",
        "print(f\"✅ Saved VAL/TEST-only CSV: {CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "f9c590d960e5410583a3e675d78377b3",
            "1f64185328f7430ca8d8644e2352b3f5",
            "c31fff516a904578ab770c1950c6797a",
            "a85a0b7ee53e412b9300895a008dd7ce",
            "3338e4a4f1fe40ef9ab421e13b135b78",
            "eb353044faa5493ba0b5e3f067a1b68f",
            "5650baa1971c4af5a37d668a81a1c995",
            "fd8ba71ea8624b8bb2d9f59a2081df9a",
            "71b19832eca14135a664057a799b6512",
            "ed740848d58f4c96beedf4b65230f716",
            "8a6f2a282141422c8119ea606ca45514"
          ]
        },
        "id": "LnlB7eLIzLa2",
        "outputId": "250b6bbd-f4ba-46bc-f0a7-08cb8f3de974"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets via kagglehub...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Initializing global model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/250M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9c590d960e5410583a3e675d78377b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TRUE FL for 12 rounds with backbone=pvt_v2_b4 ...\n",
            "Done training. Best federated VAL accuracy=0.9858 at round 12\n",
            "\n",
            "FINAL OUTPUT (VAL/TEST metrics only):\n",
            "                           setting split           dataset       acc  \\\n",
            "0  Enhanced FELCM (Best θ ds1/ds2)   VAL  ds1+ds2 weighted  0.939968   \n",
            "1      Enhanced FELCM (Best θ ds1)  TEST               ds1  0.933628   \n",
            "2      Enhanced FELCM (Best θ ds2)  TEST               ds2  0.945972   \n",
            "3          Enhanced FELCM (Best θ)  TEST   global weighted  0.943794   \n",
            "\n",
            "   precision_macro  recall_macro  f1_macro  log_loss   loss_ce  \\\n",
            "0         0.769559      0.872017  0.775791  0.202708  0.202017   \n",
            "1         0.938777      0.934354  0.934505  0.262773  0.263721   \n",
            "2         0.943232      0.941978  0.942226  0.191857  0.192667   \n",
            "3         0.942446      0.940633  0.940864  0.204368  0.205203   \n",
            "\n",
            "   auc_roc_macro_ovr  \n",
            "0                NaN  \n",
            "1           0.988137  \n",
            "2           0.993236  \n",
            "3           0.992336  \n",
            "✅ Saved checkpoint: /content/outputs/FL_GAFELCM_PVTv2B4_FUSION_checkpoint.pth\n",
            "✅ Saved VAL/TEST-only CSV: /content/outputs/VAL_TEST_METRICS_ONLY.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PVTv2-B5**"
      ],
      "metadata": {
        "id": "EvadNM3CzJ5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess, hashlib\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TRUE FL + GA-FELCM + PVTv2-B5 (FUSION) — 6 Clients (3+3)\n",
        "# Preprocessing ON + Augmentation ON + Fusion ON\n",
        "# CHANGES REQUESTED:\n",
        "#  - backbone -> PVTv2-B5\n",
        "#  - rounds -> 12\n",
        "#  - output -> only VAL/TEST metrics\n",
        "# Saves:\n",
        "#  - checkpoint\n",
        "#  - one CSV with only VAL/TEST metrics\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,  # requested\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"FL_GAFELCM_PVTv2B5_FUSION_checkpoint.pth\")\n",
        "CSV_PATH = os.path.join(OUTDIR, \"VAL_TEST_METRICS_ONLY.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"notumor\" in s or \"no tumor\" in s or \"no_tumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "print(\"Downloading datasets via kagglehub...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not locate required dataset roots\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if not idxs:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        counts[np.argmax(props)] += len(idxs) - counts.sum()\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start : start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_test_splits = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        client_test_splits.append((ds_name, k, base_gid + k, split[k].tolist()))\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])), transforms.ToTensor()])\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        return x, int(row[\"y\"]), row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=(shuffle and sampler is None), sampler=sampler,\n",
        "                      num_workers=CFG[\"num_workers\"], pin_memory=(DEVICE.type == \"cuda\"), drop_last=False,\n",
        "                      persistent_workers=(CFG[\"num_workers\"] > 0))\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(class_weights[ys]), num_samples=len(ys), replacement=True)\n",
        "\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, _, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(src, tune_idx if tune_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(src, val_idx if val_idx else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, _, gid, test_idx in client_test_splits:\n",
        "    src = test1 if ds_name == \"ds1\" else test2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    client_test_loaders.append((ds_name, gid, make_loader(src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, source_id=source_id, client_id=gid)))\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * (lap / (blur + eps)))\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(x2.shape[1]):\n",
        "                xc = x2[:, c:c+1]\n",
        "                xs = F.conv2d(F.pad(xc, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(xc * (1 - self.sharpen) + xs * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        return ((x2 - mn) / (mx - mn + eps)).clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(nn.Conv2d(c, out_dim, 1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU()) for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(nn.Conv2d(out_dim, out_dim, 3, padding=1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU())\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(nn.Linear(dim, max(8, dim // 4)), nn.ReLU(inplace=True), nn.Linear(max(8, dim // 4), dim), nn.Sigmoid())\n",
        "        self.refine = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim, dim))\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "BACKBONE_NAME = \"pvt_v2_b5\"  # requested\n",
        "\n",
        "\n",
        "class PVTv2B5_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(BACKBONE_NAME, pretrained=pretrained, features_only=True, out_indices=(0, 1, 2, 3))\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim), nn.Dropout(head_dropout), nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(), nn.Dropout(head_dropout * 0.5), nn.Linear(max(64, out_dim // 2), num_classes)\n",
        "        )\n",
        "        self.theta_mlp = nn.Sequential(nn.Linear(7, cond_dim), nn.GELU(), nn.Linear(cond_dim, cond_dim))\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "        f0, f1 = self.fuser(feats0), self.fuser(feats1)\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "        t0, t1, t_mid = self.tuner(f0), self.tuner(f1), self.tuner(f_mid)\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        (bb_params if n.startswith(\"backbone.\") else head_params).append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma, preproc_module.alpha, preproc_module.beta, preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0, preproc_module.sharpen, preproc_module.denoise\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if not all_y:\n",
        "        return {k: np.nan for k in [\"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\"]}\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "    out = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    losses = []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        losses.append(float(loss.item()))\n",
        "\n",
        "    return float(np.mean(losses))\n",
        "\n",
        "\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    sep = 0.0\n",
        "    if len(classes) >= 2:\n",
        "        centroids, vars_, sizes = [], [], []\n",
        "        for c in classes:\n",
        "            e = emb[y == c]\n",
        "            if e.size(0) < 2:\n",
        "                continue\n",
        "            mu = e.mean(dim=0)\n",
        "            centroids.append(mu)\n",
        "            vars_.append((e - mu).pow(2).sum(dim=1).mean().item())\n",
        "            sizes.append(e.size(0))\n",
        "        if len(centroids) >= 2:\n",
        "            centroids = torch.stack(centroids, dim=0)\n",
        "            gm = centroids.mean(dim=0)\n",
        "            between = sum(n * (c - gm).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "            within = float(np.mean(vars_)) if vars_ else 1e-6\n",
        "            sep = float(between / (within + 1e-6))\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None, [], 0.0\n",
        "    pop = elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)]\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "    bx, by = bx[: CFG[\"batch_size\"]].contiguous(), by[: CFG[\"batch_size\"]].contiguous()\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "    scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1], [th for _, th in scored[: CFG[\"ga_elites\"]]], float(scored[0][0])\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    total = sum(w for _, _, w in mets)\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    keys = mets[0][1].keys()\n",
        "    return {k: float(np.average([m[1].get(k, np.nan) for m in mets], weights=[m[2] for m in mets])) for k in keys}\n",
        "\n",
        "\n",
        "print(\"Initializing global model...\")\n",
        "global_model = PVTv2B5_MultiScale(NUM_CLASSES, pretrained=True, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "set_trainable_for_round(global_model, 1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values + \\\n",
        "         train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc, best_round_saved = -1.0, None\n",
        "best_model_state = None\n",
        "\n",
        "print(f\"Training TRUE FL for {CFG['rounds']} rounds with backbone={BACKBONE_NAME} ...\")\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "        else:\n",
        "            best_theta = None\n",
        "            pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = PVTv2B5_MultiScale(NUM_CLASSES, pretrained=False, head_dropout=CFG[\"head_dropout\"], cond_dim=CFG[\"cond_dim\"], num_clients=CFG[\"clients_total\"]).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "        set_trainable_for_round(local_model, rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        sched = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=sched, scaler=scaler)\n",
        "\n",
        "        met = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_rows.append({\"val_acc\": met.get(\"acc\", np.nan), \"val_size\": len(val_loader.dataset)})\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    fedavg_update(global_model, local_models, [w / wsum for w in local_weights], [n for n, p in local_models[0].named_parameters() if p.requires_grad])\n",
        "\n",
        "    lv = pd.DataFrame(local_rows)\n",
        "    round_acc = float(np.average(lv[\"val_acc\"], weights=lv[\"val_size\"])) if lv[\"val_size\"].sum() > 0 else np.nan\n",
        "    if np.isfinite(round_acc) and round_acc > best_global_acc:\n",
        "        best_global_acc = round_acc\n",
        "        best_round_saved = rnd\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "print(f\"Done training. Best federated VAL accuracy={best_global_acc:.4f} at round {best_round_saved}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# Re-run GA with the restored best global model so final VAL/TEST uses GA-FELCM (not Identity preproc)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "best_theta_by_client = {}\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, tune_loader, _ = client_loaders[k]\n",
        "    ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "    elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "    th, _, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "    best_theta_by_client[k] = th\n",
        "\n",
        "\n",
        "def preproc_for_client(client_id: int):\n",
        "    th = best_theta_by_client.get(client_id)\n",
        "    return theta_to_module(th).to(DEVICE) if th is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = preproc_for_client(k)\n",
        "    met = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = preproc_for_client(gid)\n",
        "        met = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((gid, met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets) if mets else {}\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([\n",
        "    (0, test_ds1, len(test1)),\n",
        "    (1, test_ds2, len(test2)),\n",
        "])\n",
        "\n",
        "\n",
        "def compact_metrics(m):\n",
        "    keep = [\"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"log_loss\", \"loss_ce\", \"auc_roc_macro_ovr\"]\n",
        "    return {k: float(m[k]) for k in keep if k in m}\n",
        "\n",
        "\n",
        "val_test_df = pd.DataFrame([\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **compact_metrics(val_best)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **compact_metrics(test_ds1)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **compact_metrics(test_ds2)},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **compact_metrics(global_test)},\n",
        "])\n",
        "\n",
        "print(\"\\nFINAL OUTPUT (VAL/TEST metrics only):\")\n",
        "print(val_test_df)\n",
        "\n",
        "checkpoint = {\n",
        "    \"state_dict\": {k: v.detach().cpu() for k, v in global_model.state_dict().items()},\n",
        "    \"config\": CFG,\n",
        "    \"seed\": SEED,\n",
        "    \"device_used\": str(DEVICE),\n",
        "    \"dataset1_raw_root\": DS1_ROOT,\n",
        "    \"dataset2_root\": DS2_ROOT,\n",
        "    \"labels\": labels,\n",
        "    \"label2id\": label2id,\n",
        "    \"id2label\": id2label,\n",
        "    \"num_classes\": NUM_CLASSES,\n",
        "    \"backbone_name\": BACKBONE_NAME,\n",
        "    \"best_round_saved\": best_round_saved,\n",
        "    \"best_val_acc\": best_global_acc,\n",
        "    \"final_val_federated\": val_best,\n",
        "    \"final_test_ds1\": test_ds1,\n",
        "    \"final_test_ds2\": test_ds2,\n",
        "    \"final_test_global_weighted\": global_test,\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)\n",
        "val_test_df.to_csv(CSV_PATH, index=False)\n",
        "print(f\"✅ Saved checkpoint: {MODEL_PATH}\")\n",
        "print(f\"✅ Saved VAL/TEST-only CSV: {CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801,
          "referenced_widgets": [
            "67ad3242a5a54175a17e09f6b78d6d49",
            "dde73568768d4395b852a30600526b84",
            "43221b2bc1e445dfabaa20ea16af1f6f",
            "a74c801b6431434ab462e0023566ec46",
            "6c3280db53774e76bd0b1d14df929ad7",
            "ceb0e869483d42dd8b89b207bb14d8f9",
            "45b95f8d422f4f8fa321652993984f17",
            "6572f5edd2154a33b10511639b23cd81",
            "f6918d56c3c84d7fbf8c4e5dfb0624a2",
            "7bbbb414514f40598fb3083cb00bff5b",
            "bd9facbe6bbb4fe7a67b1abbf782e3c4"
          ]
        },
        "id": "YI5MEpbSzM4n",
        "outputId": "37abcb4d-461f-41c2-8e44-6d6b00737bcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets via kagglehub...\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130M/130M [00:00<00:00, 187MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/orvile/pmram-bangladeshi-brain-cancer-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161M/161M [00:01<00:00, 104MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing global model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67ad3242a5a54175a17e09f6b78d6d49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TRUE FL for 12 rounds with backbone=pvt_v2_b5 ...\n",
            "Done training. Best federated VAL accuracy=0.9779 at round 10\n",
            "\n",
            "FINAL OUTPUT (VAL/TEST metrics only):\n",
            "                           setting split           dataset       acc  \\\n",
            "0  Enhanced FELCM (Best θ ds1/ds2)   VAL  ds1+ds2 weighted  0.908373   \n",
            "1      Enhanced FELCM (Best θ ds1)  TEST               ds1  0.907080   \n",
            "2      Enhanced FELCM (Best θ ds2)  TEST               ds2  0.939336   \n",
            "3          Enhanced FELCM (Best θ)  TEST   global weighted  0.933646   \n",
            "\n",
            "   precision_macro  recall_macro  f1_macro  log_loss   loss_ce  \\\n",
            "0         0.738625      0.926706  0.742622  0.277366  0.269406   \n",
            "1         0.903363      0.908528  0.903041  0.288221  0.288536   \n",
            "2         0.934881      0.933925  0.933910  0.217846  0.218045   \n",
            "3         0.929320      0.929444  0.928464  0.230262  0.230481   \n",
            "\n",
            "   auc_roc_macro_ovr  \n",
            "0                NaN  \n",
            "1           0.986038  \n",
            "2           0.992015  \n",
            "3           0.990961  \n",
            "✅ Saved checkpoint: /content/outputs/FL_GAFELCM_PVTv2B5_FUSION_checkpoint.pth\n",
            "✅ Saved VAL/TEST-only CSV: /content/outputs/VAL_TEST_METRICS_ONLY.csv\n"
          ]
        }
      ]
    }
  ]
}