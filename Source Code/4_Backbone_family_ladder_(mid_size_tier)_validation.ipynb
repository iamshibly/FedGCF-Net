{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bacec15a8bfb4c7da254033ef72bda4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_054fd00f73b8460e9dc145bdb34c4325",
              "IPY_MODEL_49a37df57d404d2fb438aef8e1fd612b",
              "IPY_MODEL_c1219f2479624620b0a67ad4351bc400"
            ],
            "layout": "IPY_MODEL_3a8e02722b044940991d1c03b380554c"
          }
        },
        "054fd00f73b8460e9dc145bdb34c4325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b8cff17defd4105824b12880c63465b",
            "placeholder": "​",
            "style": "IPY_MODEL_8c6375db1eeb408b9ed06a5d65a56204",
            "value": "model.safetensors: 100%"
          }
        },
        "49a37df57d404d2fb438aef8e1fd612b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237ce3e05deb41fb80ffe21ebf4cba70",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8879ddd6cf9842f3a0a83d8016905c37",
            "value": 346284714
          }
        },
        "c1219f2479624620b0a67ad4351bc400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5f76908813493689cbcb2a7f4a0065",
            "placeholder": "​",
            "style": "IPY_MODEL_969b9a2bb59b42aeb8e5472ef6cbca3d",
            "value": " 346M/346M [00:05&lt;00:00, 242MB/s]"
          }
        },
        "3a8e02722b044940991d1c03b380554c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8cff17defd4105824b12880c63465b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6375db1eeb408b9ed06a5d65a56204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "237ce3e05deb41fb80ffe21ebf4cba70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8879ddd6cf9842f3a0a83d8016905c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a5f76908813493689cbcb2a7f4a0065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969b9a2bb59b42aeb8e5472ef6cbca3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4679cca3581d44e9944d0146f803efe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5ea707fe0474703b3e7c6f263fc6f83",
              "IPY_MODEL_40e02610c2c54ca6a8d58bcd7a242257",
              "IPY_MODEL_b0e4e46938f04442b957f63418fc3d27"
            ],
            "layout": "IPY_MODEL_b78e216b94b24782a3873401170436e4"
          }
        },
        "d5ea707fe0474703b3e7c6f263fc6f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6429648e6144bf89b758c4f45e876d",
            "placeholder": "​",
            "style": "IPY_MODEL_b35f2bbaded047cea966ba737549d26e",
            "value": "model.safetensors: 100%"
          }
        },
        "40e02610c2c54ca6a8d58bcd7a242257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a88647dff6416ba5e7f6f11d8af368",
            "max": 114286722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92d933e3cae849229acfb2b7288522c1",
            "value": 114286722
          }
        },
        "b0e4e46938f04442b957f63418fc3d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c4761d6f6747d8aff4f6f2ff37f990",
            "placeholder": "​",
            "style": "IPY_MODEL_abcd0e0de51c426ca6af4dd51f5b1be1",
            "value": " 114M/114M [00:01&lt;00:00, 93.4MB/s]"
          }
        },
        "b78e216b94b24782a3873401170436e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6429648e6144bf89b758c4f45e876d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35f2bbaded047cea966ba737549d26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6a88647dff6416ba5e7f6f11d8af368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92d933e3cae849229acfb2b7288522c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4c4761d6f6747d8aff4f6f2ff37f990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abcd0e0de51c426ca6af4dd51f5b1be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Backbone family ladder (mid-size tier)\n",
        "\n",
        "ResNet-50\n",
        "\n",
        "DenseNet-121\n",
        "\n",
        "EfficientNet-B0 (or B3)\n",
        "\n",
        "ConvNeXt-T\n",
        "\n",
        "Swin-T\n",
        "\n",
        "ViT-B/16 (or DeiT-B)"
      ],
      "metadata": {
        "id": "BV15uIx6heDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DeiT-B**"
      ],
      "metadata": {
        "id": "u-LzRF0C3Rwx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533,
          "referenced_widgets": [
            "bacec15a8bfb4c7da254033ef72bda4e",
            "054fd00f73b8460e9dc145bdb34c4325",
            "49a37df57d404d2fb438aef8e1fd612b",
            "c1219f2479624620b0a67ad4351bc400",
            "3a8e02722b044940991d1c03b380554c",
            "8b8cff17defd4105824b12880c63465b",
            "8c6375db1eeb408b9ed06a5d65a56204",
            "237ce3e05deb41fb80ffe21ebf4cba70",
            "8879ddd6cf9842f3a0a83d8016905c37",
            "4a5f76908813493689cbcb2a7f4a0065",
            "969b9a2bb59b42aeb8e5472ef6cbca3d"
          ]
        },
        "id": "2Zynyc0ZhXbr",
        "outputId": "11d22806-9d1c-4f7c-c737-df5a09a94c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130M/130M [00:06<00:00, 20.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/orvile/pmram-bangladeshi-brain-cancer-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161M/161M [00:08<00:00, 19.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bacec15a8bfb4c7da254033ef72bda4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.930490         0.755383      0.941059  0.775142            0.957063         0.930490     0.939449  0.259749                NaN 0.251492     5.450670\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.867257         0.874717      0.866663  0.861529            0.878006         0.867257     0.863929  0.416327           0.978740 0.410909     2.527019\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.921327         0.917508      0.918532  0.915784            0.921755         0.921327     0.919280  0.270578           0.986869 0.266299     9.511256\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.911788         0.909959      0.909381  0.906212            0.914036         0.911788     0.909515  0.296292           0.985435 0.291812     8.279064\n"
          ]
        }
      ],
      "source": [
        "import os, time, math, random, sys, subprocess, hashlib\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, confusion_matrix, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s: return \"glioma\"\n",
        "    if \"meningioma\" in s: return \"meningioma\"\n",
        "    if \"pituitary\" in s: return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s: return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl: sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\": sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl: sc += 3\n",
        "            if \"augmented\" in pl: sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class DeiTBBackbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.deit = timm.create_model(\"deit_base_patch16_224\", pretrained=pretrained)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        x = self.deit.patch_embed(x)\n",
        "\n",
        "        cls = self.deit.cls_token.expand(b, -1, -1)\n",
        "        if getattr(self.deit, \"dist_token\", None) is not None:\n",
        "            dist = self.deit.dist_token.expand(b, -1, -1)\n",
        "            x = torch.cat((cls, dist, x), dim=1)\n",
        "            token_offset = 2\n",
        "        else:\n",
        "            x = torch.cat((cls, x), dim=1)\n",
        "            token_offset = 1\n",
        "\n",
        "        x = x + self.deit.pos_embed\n",
        "        x = self.deit.pos_drop(x)\n",
        "\n",
        "        gh = h // self.deit.patch_embed.patch_size[0]\n",
        "        gw = w // self.deit.patch_embed.patch_size[1]\n",
        "\n",
        "        feats = []\n",
        "        for i, blk in enumerate(self.deit.blocks):\n",
        "            x = blk(x)\n",
        "            if i in {2, 5, 8, 11}:\n",
        "                tok = x[:, token_offset:, :]\n",
        "                f = tok.transpose(1, 2).reshape(b, tok.shape[-1], gh, gw)\n",
        "                feats.append(f)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class DeiTB_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = DeiTBBackbone(pretrained=pretrained)\n",
        "        in_channels = [768, 768, 768, 768]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        # Signature-compatible with the original pipeline API.\n",
        "        # Current DeiT model does not return internal gate tensors.\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    total = sum(w for _, w in mets)\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = DeiTB_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = DeiTB_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DenseNet-121**"
      ],
      "metadata": {
        "id": "hNV64uEl2nPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class DenseNet121Backbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        weights = models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        dnet = models.densenet121(weights=weights)\n",
        "        self.features = dnet.features\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = []\n",
        "        x = self.features.conv0(x)\n",
        "        x = self.features.norm0(x)\n",
        "        x = self.features.relu0(x)\n",
        "        x = self.features.pool0(x)\n",
        "\n",
        "        x = self.features.denseblock1(x)\n",
        "        feats.append(x)\n",
        "        x = self.features.transition1(x)\n",
        "\n",
        "        x = self.features.denseblock2(x)\n",
        "        feats.append(x)\n",
        "        x = self.features.transition2(x)\n",
        "\n",
        "        x = self.features.denseblock3(x)\n",
        "        feats.append(x)\n",
        "        x = self.features.transition3(x)\n",
        "\n",
        "        x = self.features.denseblock4(x)\n",
        "        x = self.features.norm5(x)\n",
        "        feats.append(x)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class DenseNet121_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = DenseNet121Backbone(pretrained=pretrained)\n",
        "        in_channels = [256, 512, 1024, 1024]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = DenseNet121_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = DenseNet121_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHTBbd523v58",
        "outputId": "9619a3dc-6fc3-4508-c286-fadf0a61758b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 192MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.622433         0.716489      0.672254  0.508683            0.898396         0.622433     0.643419  1.256511                NaN 1.271830     3.113227\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.584071         0.835465      0.580947  0.552589            0.838480         0.584071     0.560216  1.256331           0.896351 1.243431     2.325316\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.590521         0.820432      0.584873  0.538577            0.835699         0.590521     0.553285  1.318358           0.879787 1.320917     6.863452\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.589383         0.823084      0.584180  0.541049            0.836189         0.589383     0.554508  1.307414           0.882710 1.307246     6.062813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet-50**"
      ],
      "metadata": {
        "id": "3uZmasWehiVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class ResNet50Backbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        weights = models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None\n",
        "        net = models.resnet50(weights=weights)\n",
        "        self.conv1 = net.conv1\n",
        "        self.bn1 = net.bn1\n",
        "        self.relu = net.relu\n",
        "        self.maxpool = net.maxpool\n",
        "        self.layer1 = net.layer1\n",
        "        self.layer2 = net.layer2\n",
        "        self.layer3 = net.layer3\n",
        "        self.layer4 = net.layer4\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        feats.append(x)\n",
        "        x = self.layer2(x)\n",
        "        feats.append(x)\n",
        "        x = self.layer3(x)\n",
        "        feats.append(x)\n",
        "        x = self.layer4(x)\n",
        "        feats.append(x)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class ResNet50_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = ResNet50Backbone(pretrained=pretrained)\n",
        "        in_channels = [256, 512, 1024, 2048]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = ResNet50_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = ResNet50_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twj76W782pGb",
        "outputId": "e352e083-7ef7-4c0a-8a01-dcbe77a843e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/orvile/pmram-bangladeshi-brain-cancer-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161M/161M [00:09<00:00, 18.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 148MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.739336         0.701299      0.705339  0.612545            0.909203         0.739336     0.775984  0.796141                NaN 0.788748     2.829313\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.672566         0.785990      0.669170  0.646711            0.788236         0.672566     0.652030  1.046664           0.900620 1.051847     2.016313\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.734597         0.825398      0.725817  0.712547            0.831364         0.734597     0.723580  0.842489           0.934326 0.843561     6.288494\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.723653         0.818446      0.715823  0.700932            0.823755         0.723653     0.710957  0.878510           0.928379 0.880308     5.534776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EfficientNet-B0**"
      ],
      "metadata": {
        "id": "4Tma3kqZ28KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class EfficientNetB0Backbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        net = models.efficientnet_b0(weights=weights)\n",
        "        self.features = net.features\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = []\n",
        "        for i, block in enumerate(self.features):\n",
        "            x = block(x)\n",
        "            if i in {2, 3, 5, 8}:\n",
        "                feats.append(x)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class EfficientNetB0_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = EfficientNetB0Backbone(pretrained=pretrained)\n",
        "        in_channels = [24, 40, 112, 1280]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = EfficientNetB0_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = EfficientNetB0_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "Xi6bhJeY29bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0246da2c-3dcc-46db-f963-b390f173cd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.725118         0.687829      0.780957  0.624834            0.876695         0.725118     0.749311  0.778805                NaN 0.771438     1.958183\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.703540         0.817952      0.697915  0.685557            0.825652         0.703540     0.694738  0.905015           0.933505 0.894178     1.528389\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.745024         0.819638      0.736473  0.720858            0.825738         0.745024     0.731872  0.777580           0.944821 0.773610     4.190761\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.737705         0.819340      0.729670  0.714630            0.825723         0.737705     0.725320  0.800063           0.942824 0.794881     3.721053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EfficientNet-B3**"
      ],
      "metadata": {
        "id": "WQ4AIynL29xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class EfficientNetB3Backbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        weights = models.EfficientNet_B3_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        net = models.efficientnet_b3(weights=weights)\n",
        "        self.features = net.features\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = []\n",
        "        for i, block in enumerate(self.features):\n",
        "            x = block(x)\n",
        "            if i in {2, 3, 5, 8}:\n",
        "                feats.append(x)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class EfficientNetB3_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = EfficientNetB3Backbone(pretrained=pretrained)\n",
        "        in_channels = [32, 48, 136, 1536]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = EfficientNetB3_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = EfficientNetB3_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "sqqcLlJn3CYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6443d241-3dff-4ee5-8040-304ee234ead5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47.2M/47.2M [00:00<00:00, 74.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.878357         0.720307      0.787387  0.704651            0.933898         0.878357     0.902432  0.384337                NaN 0.373188     2.422866\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.823009         0.840227      0.828367  0.822599            0.846353         0.823009     0.823649  0.510442           0.962610 0.506676     1.961017\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.890047         0.888522      0.887609  0.885975            0.896895         0.890047     0.891488  0.357523           0.975532 0.355066     5.279348\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.878220         0.880001      0.877157  0.874794            0.887978         0.878220     0.879520  0.384502           0.973252 0.381814     4.693913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ConvNeXt-T**"
      ],
      "metadata": {
        "id": "ybX2kLrq3CIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class ConvNeXtTinyBackbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        weights = models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        net = models.convnext_tiny(weights=weights)\n",
        "        self.features = net.features\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = []\n",
        "        # features layout (torchvision convnext_tiny):\n",
        "        # 0: stem, 1: stage1, 2: downsample, 3: stage2, 4: downsample,\n",
        "        # 5: stage3, 6: downsample, 7: stage4\n",
        "        x = self.features[0](x)\n",
        "        x = self.features[1](x)\n",
        "        feats.append(x)\n",
        "\n",
        "        x = self.features[2](x)\n",
        "        x = self.features[3](x)\n",
        "        feats.append(x)\n",
        "\n",
        "        x = self.features[4](x)\n",
        "        x = self.features[5](x)\n",
        "        feats.append(x)\n",
        "\n",
        "        x = self.features[6](x)\n",
        "        x = self.features[7](x)\n",
        "        feats.append(x)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class ConvNeXtTiny_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = ConvNeXtTinyBackbone(pretrained=pretrained)\n",
        "        in_channels = [96, 192, 384, 768]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = ConvNeXtTiny_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = ConvNeXtTiny_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "sksrolHP3JCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dc278c-d445-4dfd-b6fa-636c93be6dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109M/109M [00:00<00:00, 129MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.944708         0.798204      0.968297  0.817921            0.965771         0.944708     0.952090  0.218650                NaN 0.216986     3.179074\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.933628         0.933729      0.931392  0.930280            0.935778         0.933628     0.932495  0.227647           0.986707 0.226494     2.807986\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.931754         0.930454      0.926140  0.926722            0.932187         0.931754     0.930538  0.252154           0.990907 0.254234     8.024479\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.932084         0.931032      0.927067  0.927349            0.932820         0.932084     0.930883  0.247830           0.990166 0.249340     7.104161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Swin-T**"
      ],
      "metadata": {
        "id": "x8VQA4uE3CFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class SwinTinyBackbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.swin = timm.create_model(\n",
        "            \"swin_tiny_patch4_window7_224\",\n",
        "            pretrained=pretrained,\n",
        "            features_only=True,\n",
        "            out_indices=(0, 1, 2, 3),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_nchw(feat):\n",
        "        # timm Swin features are commonly NHWC (B, H, W, C) while CNN fusers expect NCHW.\n",
        "        if feat.ndim != 4:\n",
        "            return feat\n",
        "        # If already NCHW, keep as-is.\n",
        "        if feat.shape[1] in {96, 192, 384, 768} and feat.shape[-1] not in {96, 192, 384, 768}:\n",
        "            return feat\n",
        "        # Convert NHWC -> NCHW.\n",
        "        if feat.shape[-1] in {96, 192, 384, 768}:\n",
        "            return feat.permute(0, 3, 1, 2).contiguous()\n",
        "        # Fallback: pick the smallest spatial dims as H/W and move channel dim to position 1.\n",
        "        b, d1, d2, d3 = feat.shape\n",
        "        spatial = sorted([(1, d1), (2, d2), (3, d3)], key=lambda x: x[1])[:2]\n",
        "        sp_idx = {i for i, _ in spatial}\n",
        "        ch_idx = [i for i in (1, 2, 3) if i not in sp_idx][0]\n",
        "        order = [0, ch_idx] + sorted(sp_idx)\n",
        "        return feat.permute(*order).contiguous()\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.swin(x)\n",
        "        return [self._to_nchw(f) for f in feats]\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class SwinTiny_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = SwinTinyBackbone(pretrained=pretrained)\n",
        "        in_channels = [96, 192, 384, 768]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = SwinTiny_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = SwinTiny_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "IgoJbrNj3NA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390,
          "referenced_widgets": [
            "4679cca3581d44e9944d0146f803efe0",
            "d5ea707fe0474703b3e7c6f263fc6f83",
            "40e02610c2c54ca6a8d58bcd7a242257",
            "b0e4e46938f04442b957f63418fc3d27",
            "b78e216b94b24782a3873401170436e4",
            "3e6429648e6144bf89b758c4f45e876d",
            "b35f2bbaded047cea966ba737549d26e",
            "f6a88647dff6416ba5e7f6f11d8af368",
            "92d933e3cae849229acfb2b7288522c1",
            "e4c4761d6f6747d8aff4f6f2ff37f990",
            "abcd0e0de51c426ca6af4dd51f5b1be1"
          ]
        },
        "outputId": "9066c3d4-d500-4622-9e56-b6a425ed4880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4679cca3581d44e9944d0146f803efe0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.939968         0.762435      0.867149  0.774771            0.966980         0.939968     0.949871  0.234568                NaN 0.230608     3.481177\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.920354         0.922945      0.919402  0.919116            0.922960         0.920354     0.919661  0.286956           0.982562 0.286032     2.254558\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.925118         0.923275      0.918953  0.918404            0.925842         0.925118     0.923018  0.274266           0.981405 0.275690     7.025684\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.924278         0.923217      0.919032  0.918530            0.925334         0.924278     0.922426  0.276505           0.981609 0.277514     6.183940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ViT-B/16**"
      ],
      "metadata": {
        "id": "bxKhWcaI3NRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, random, sys, subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    log_loss, roc_auc_score,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Install deps (Colab)\n",
        "# -------------------------\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "def _safe_import_torch():\n",
        "    \"\"\"\n",
        "    Robust torch import for notebook runtimes.\n",
        "    Fixes common 'partially initialized module torch has no attribute nn'\n",
        "    by clearing stale torch modules from sys.modules before import.\n",
        "    \"\"\"\n",
        "    for k in list(sys.modules.keys()):\n",
        "        if k == \"torch\" or k.startswith(\"torch.\"):\n",
        "            sys.modules.pop(k, None)\n",
        "\n",
        "    import torch  # noqa: F401\n",
        "    import torch.nn as nn  # noqa: F401\n",
        "    import torch.nn.functional as F  # noqa: F401\n",
        "    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler  # noqa: F401\n",
        "    return torch, nn, F, Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "\n",
        "try:\n",
        "    torch, nn, F, Dataset, DataLoader, WeightedRandomSampler = _safe_import_torch()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Torch import failed. In notebook runtimes, restart the runtime/kernel and run this script again. \"\n",
        "        \"Also ensure there is no local file/folder named 'torch'. Original error: \" + str(e)\n",
        "    )\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "try:\n",
        "    from torchvision import transforms, models\n",
        "except Exception:\n",
        "    pip_install(\"torchvision\")\n",
        "    from torchvision import transforms, models\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"use_augmentation\": True,\n",
        "    \"cond_dim\": 128,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "    \"quick_hash_subset_per_split\": 300,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm[\"path\"] = dfm[\"path\"].astype(str)\n",
        "    dfm[\"label\"] = dfm[\"label\"].astype(str)\n",
        "    dfm[\"source\"] = dfm[\"source\"].astype(str)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(lambda x: os.path.basename(x))\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start: start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(\n",
        "            idxs,\n",
        "            test_size=tune_frac,\n",
        "            stratify=yk,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            rem_idx,\n",
        "            test_size=val_frac,\n",
        "            stratify=yk2,\n",
        "            random_state=SEED,\n",
        "        )\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "if CFG[\"use_augmentation\"]:\n",
        "    TRAIN_TFMS = transforms.Compose([\n",
        "        transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    TRAIN_TFMS = EVAL_TFMS\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            k = 3\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), k, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        C_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * C_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c: c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    gamma = random.uniform(0.7, 1.4)\n",
        "    alpha = random.uniform(0.15, 0.55)\n",
        "    beta = random.uniform(3.0, 9.0)\n",
        "    tau = random.uniform(1.8, 3.2)\n",
        "    blur_k = random.choice([3, 5, 7])\n",
        "    sharpen = random.uniform(0.0, 0.25)\n",
        "    denoise = random.uniform(0.0, 0.2)\n",
        "    return (gamma, alpha, beta, tau, blur_k, sharpen, denoise)\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "def theta_str(th):\n",
        "    if th is None:\n",
        "        return \"None\"\n",
        "    g, a, b, t, k, sh, dn = th\n",
        "    return f\"(γ={g:.2f}, α={a:.2f}, β={b:.1f}, τ={t:.1f}, k={k}, sh={sh:.2f}, dn={dn:.2f})\"\n",
        "\n",
        "\n",
        "IDENTITY_PRE = nn.Identity().to(DEVICE)\n",
        "\n",
        "\n",
        "class ViTB16Backbone(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        weights = models.ViT_B_16_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        self.vit = models.vit_b_16(weights=weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        x = self.vit._process_input(x)\n",
        "        n = x.shape[0]\n",
        "\n",
        "        cls = self.vit.class_token.expand(n, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1)\n",
        "        x = self.vit.encoder(x)\n",
        "\n",
        "        tok = x[:, 1:, :]\n",
        "        gh = h // self.vit.patch_size\n",
        "        gw = w // self.vit.patch_size\n",
        "        feat = tok.transpose(1, 2).reshape(b, tok.shape[-1], gh, gw)\n",
        "\n",
        "        # Keep the same 4-scale interface expected by the fuser.\n",
        "        f1 = F.interpolate(feat, scale_factor=4.0, mode=\"bilinear\", align_corners=False)\n",
        "        f2 = F.interpolate(feat, scale_factor=2.0, mode=\"bilinear\", align_corners=False)\n",
        "        f3 = feat\n",
        "        f4 = F.avg_pool2d(feat, kernel_size=2, stride=2)\n",
        "        return [f1, f2, f3, f4]\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class ViTB16_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = ViTB16Backbone(pretrained=pretrained)\n",
        "        in_channels = [768, 768, 768, 768]\n",
        "        out_dim = 512\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        cond = self.theta_mlp(theta_vec)\n",
        "        cond = cond + self.source_emb(source_id) + self.client_emb(client_id)\n",
        "        return self.cond_norm(cond)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = []\n",
        "    within_vars = []\n",
        "    sizes = []\n",
        "    for c in classes:\n",
        "        mask = y == c\n",
        "        e = emb[mask]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y, use_separability=True):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "    sep = 0.0\n",
        "    if use_separability:\n",
        "        emb = backbone_frozen(x_n)\n",
        "        if isinstance(emb, (list, tuple)):\n",
        "            emb = emb[-1]\n",
        "            emb = emb.mean(dim=(2, 3))\n",
        "        sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    if use_separability:\n",
        "        return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "    return 0.60 * contrast + 0.35 * dyn_range - 0.5 * cost\n",
        "\n",
        "\n",
        "def _safe_first_batch(dl):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl))\n",
        "        return bx, by\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval, elite_pool, use_separability=True):\n",
        "    bx, by = _safe_first_batch(dl_for_eval)\n",
        "    if bx is None:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            child = mutate(crossover(p1, p2), p=0.75)\n",
        "            new_pop.append(child)\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by, use_separability), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    best_fit = float(scored[0][0])\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, best_fit\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "            for c in range(num_classes):\n",
        "                yc = (y_true == c).astype(int)\n",
        "                if yc.sum() > 0 and yc.sum() < len(yc):\n",
        "                    out[f\"auc_class_{c}\"] = float(roc_auc_score(yc, p_pred[:, c]))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, return_gates=False):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if len(all_y) == 0:\n",
        "        met = {k: np.nan for k in [\n",
        "            \"loss_ce\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\", \"eval_time_s\"\n",
        "        ]}\n",
        "        return met, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, NUM_CLASSES))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None, grad_clip=1.0):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if grad_clip and grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    new_sd = {}\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        new_sd[name] = acc\n",
        "    for name, t in new_sd.items():\n",
        "        gsd[name].copy_(t.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:10]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    keys = mets[0][0].keys()\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        vals = [m[0].get(k, np.nan) for m in mets]\n",
        "        ws = [m[1] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ========== DATA ==========\n",
        "print(\"Downloading datasets...\")\n",
        "ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "DS1_ROOT = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "DS2_ROOT = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "\n",
        "if DS1_ROOT is None or DS2_ROOT is None:\n",
        "    raise RuntimeError(\"Could not detect dataset roots.\")\n",
        "\n",
        "df1 = enforce_labels(build_df_from_root(DS1_ROOT, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\"))\n",
        "df2 = enforce_labels(build_df_from_root(DS2_ROOT, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\"))\n",
        "\n",
        "train1, val1, test1 = split_dataset(df1)\n",
        "train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "client_splits = []\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds1\", k, k, tr, tune, va))\n",
        "for k in range(n_per_ds):\n",
        "    tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "    client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune, va))\n",
        "\n",
        "client_loaders = []\n",
        "for ds_name, local_id, gid, tr_idx, tune_idx, val_idx in client_splits:\n",
        "    df_src = train1 if ds_name == \"ds1\" else train2\n",
        "    source_id = 0 if ds_name == \"ds1\" else 1\n",
        "    sampler = make_weighted_sampler(df_src, tr_idx, NUM_CLASSES)\n",
        "    tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "    tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "    val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "    client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "client_test_loaders = []\n",
        "for ds_name, test_df, base_gid in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "    idxs = list(range(len(test_df)))\n",
        "    random.shuffle(idxs)\n",
        "    split = np.array_split(idxs, n_per_ds)\n",
        "    for k in range(n_per_ds):\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "        t_loader = make_loader(test_df, split[k].tolist(), CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=base_gid + k)\n",
        "        client_test_loaders.append((ds_name, base_gid + k, t_loader))\n",
        "\n",
        "# ========== MODEL ==========\n",
        "global_model = ViTB16_MultiScale(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    pretrained=True,\n",
        "    head_dropout=CFG[\"head_dropout\"],\n",
        "    cond_dim=CFG[\"cond_dim\"],\n",
        "    num_clients=CFG[\"clients_total\"],\n",
        ").to(DEVICE)\n",
        "\n",
        "set_trainable_for_round(global_model, rnd=1)\n",
        "backbone_frozen = global_model.backbone.eval()\n",
        "for p in backbone_frozen.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "counts = counts1 + counts2\n",
        "w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "w = w / max(1e-6, w.mean())\n",
        "class_w = torch.tensor(w, device=DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "# ========== TRAIN (silent per-round) ==========\n",
        "elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "best_global_acc = -1.0\n",
        "best_model_state = None\n",
        "best_theta_ds1 = None\n",
        "best_theta_ds2 = None\n",
        "\n",
        "for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "    local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "        ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "        elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "            best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool, use_separability=True)\n",
        "            elite_pool.extend(top_thetas)\n",
        "            elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "            pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else IDENTITY_PRE\n",
        "        else:\n",
        "            pre_k = IDENTITY_PRE\n",
        "\n",
        "        if ds_name == \"ds1\":\n",
        "            elite_pool_ds1 = elite_pool\n",
        "        else:\n",
        "            elite_pool_ds2 = elite_pool\n",
        "\n",
        "        local_model = ViTB16_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=False,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "        local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "        set_trainable_for_round(local_model, rnd=rnd)\n",
        "        opt = make_optimizer(local_model)\n",
        "\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model=global_model, scheduler=scheduler, scaler=scaler, grad_clip=CFG[\"grad_clip\"])\n",
        "\n",
        "        met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k)\n",
        "        local_models.append(local_model)\n",
        "        local_weights.append(len(tr_loader.dataset))\n",
        "        local_rows.append((met_loc, len(val_loader.dataset)))\n",
        "\n",
        "    wsum = sum(local_weights)\n",
        "    weights = [w / wsum for w in local_weights]\n",
        "    trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "    fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "        best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2])\n",
        "    if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "        best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2])\n",
        "\n",
        "    global_metrics = weighted_aggregate(local_rows)\n",
        "    if np.isfinite(global_metrics.get(\"acc\", np.nan)) and global_metrics[\"acc\"] > best_global_acc:\n",
        "        best_global_acc = float(global_metrics[\"acc\"])\n",
        "        best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "if best_model_state is not None:\n",
        "    global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "# ========== FINAL METRICS ONLY ==========\n",
        "pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds1 is not None) else IDENTITY_PRE\n",
        "pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (CFG[\"use_preprocessing\"] and best_theta_ds2 is not None) else IDENTITY_PRE\n",
        "\n",
        "val_metrics_clients = []\n",
        "for k in range(CFG[\"clients_total\"]):\n",
        "    _, _, val_loader = client_loaders[k]\n",
        "    pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "    met, _, _ = evaluate_full(global_model, val_loader, pre)\n",
        "    val_metrics_clients.append((met, len(val_loader.dataset)))\n",
        "val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "\n",
        "def eval_test_per_dataset(ds_name):\n",
        "    mets = []\n",
        "    for ds, gid, t_loader in client_test_loaders:\n",
        "        if ds != ds_name:\n",
        "            continue\n",
        "        pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, t_loader, pre)\n",
        "        mets.append((met, len(t_loader.dataset)))\n",
        "    return weighted_aggregate(mets)\n",
        "\n",
        "\n",
        "test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "global_test = weighted_aggregate([(test_ds1, len(test1)), (test_ds2, len(test2))])\n",
        "\n",
        "columns = [\n",
        "    \"setting\", \"split\", \"dataset\",\n",
        "    \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "    \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "]\n",
        "\n",
        "rows = [\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1/ds2)\", \"split\": \"VAL\", \"dataset\": \"ds1+ds2 weighted\", **val_best},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds1)\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ ds2)\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "    {\"setting\": \"Enhanced FELCM (Best θ)\", \"split\": \"TEST\", \"dataset\": \"global weighted\", **global_test},\n",
        "]\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n",
        "for c in columns:\n",
        "    if c not in final_df.columns:\n",
        "        final_df[c] = np.nan\n",
        "final_df = final_df[columns]\n",
        "\n",
        "print(\"\\nFinal output metrics:\")\n",
        "print(final_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "Dcb8gDym3RSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69278291-03b2-4f4a-cd89-60b821f999c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets...\n",
            "Using Colab cache for faster access to the 'preprocessed-brain-mri-scans-for-tumors-detection' dataset.\n",
            "Using Colab cache for faster access to the 'pmram-bangladeshi-brain-cancer-mri-dataset' dataset.\n",
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 330M/330M [00:01<00:00, 199MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output metrics:\n",
            "                        setting split          dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Enhanced FELCM (Best θ ds1/ds2)   VAL ds1+ds2 weighted 0.927330         0.758157      0.954026  0.774016            0.960339         0.927330     0.938602  0.276077                NaN 0.273979     7.235911\n",
            "    Enhanced FELCM (Best θ ds1)  TEST              ds1 0.915929         0.925593      0.916968  0.915256            0.926273         0.915929     0.915114  0.339266           0.986697 0.343778     3.821958\n",
            "    Enhanced FELCM (Best θ ds2)  TEST              ds2 0.937441         0.937293      0.932836  0.933625            0.938009         0.937441     0.936365  0.247798           0.988816 0.248896    13.663844\n",
            "        Enhanced FELCM (Best θ)  TEST  global weighted 0.933646         0.935229      0.930037  0.930384            0.935939         0.933646     0.932616  0.263935           0.988442 0.265635    11.927492\n"
          ]
        }
      ]
    }
  ]
}