{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e1e5e21390c4cce86bedd801fb2c5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfa2a5ad9bf142ceabf9b6f61e88f14e",
              "IPY_MODEL_652e21c852db4d33ad1a3122cb319763",
              "IPY_MODEL_87b80b4eddcd4fa98b634f961e27b4f6"
            ],
            "layout": "IPY_MODEL_5412a1cb438846cbab477cbdc003e311"
          }
        },
        "cfa2a5ad9bf142ceabf9b6f61e88f14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7eeaec5ec3463c8767eeb17c3b5180",
            "placeholder": "​",
            "style": "IPY_MODEL_1cf4058150784d4e852a067f8f37d7d7",
            "value": "model.safetensors: 100%"
          }
        },
        "652e21c852db4d33ad1a3122cb319763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba23dd7eaf1400d82e82fb7274eef75",
            "max": 101484732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e59747042b6467b8c7ac2fb8f9f2d59",
            "value": 101484732
          }
        },
        "87b80b4eddcd4fa98b634f961e27b4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2077e84f20c452198095771255c0753",
            "placeholder": "​",
            "style": "IPY_MODEL_28edb661897e4e7dbea2e95d42b39f9a",
            "value": " 101M/101M [00:03&lt;00:00, 38.2MB/s]"
          }
        },
        "5412a1cb438846cbab477cbdc003e311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7eeaec5ec3463c8767eeb17c3b5180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf4058150784d4e852a067f8f37d7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba23dd7eaf1400d82e82fb7274eef75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e59747042b6467b8c7ac2fb8f9f2d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2077e84f20c452198095771255c0753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28edb661897e4e7dbea2e95d42b39f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**“Local-only (no aggregation)”** means:\n",
        "\n",
        "### Meaning\n",
        "\n",
        "Each client (hospital/site/dataset-part) **trains its own model only on its own data**, and **nothing is shared/combined**.\n",
        "\n",
        "So:\n",
        "\n",
        "* **No FedAvg** (no averaging of weights)\n",
        "* **No global model**\n",
        "* **No federation rounds**\n",
        "* You end up with **6 separate models** (client_0 … client_5)\n",
        "\n",
        "### Why it’s used in your paper\n",
        "\n",
        "It answers:\n",
        "“Is federated collaboration actually helping, or would each site do fine alone?”\n",
        "\n",
        "Usually you show:\n",
        "\n",
        "* **Average performance across clients**\n",
        "* **Worst client performance**\n",
        "* Maybe **DS1 average vs DS2 average**\n",
        "\n",
        "### How to implement with your setup (conceptually)\n",
        "\n",
        "For each client (k):\n",
        "\n",
        "1. Initialize model weights\n",
        "2. Train on that client’s train loader only\n",
        "3. Evaluate on that client’s test loader\n",
        "4. Save metrics\n",
        "   Then report all 6 results (mean ± std)\n",
        "\n",
        "### How to write it in one line\n",
        "\n",
        "> **Local-only**: independent training at each client without any server aggregation or parameter sharing.\n",
        "\n",
        "If you want, I can tell you the exact minimal changes in your loop (basically: remove `fedavg_update()` and stop copying `global_model` into locals each round).\n"
      ],
      "metadata": {
        "id": "0tY39mJnNY7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962,
          "referenced_widgets": [
            "3e1e5e21390c4cce86bedd801fb2c5e5",
            "cfa2a5ad9bf142ceabf9b6f61e88f14e",
            "652e21c852db4d33ad1a3122cb319763",
            "87b80b4eddcd4fa98b634f961e27b4f6",
            "5412a1cb438846cbab477cbdc003e311",
            "8d7eeaec5ec3463c8767eeb17c3b5180",
            "1cf4058150784d4e852a067f8f37d7d7",
            "bba23dd7eaf1400d82e82fb7274eef75",
            "5e59747042b6467b8c7ac2fb8f9f2d59",
            "c2077e84f20c452198095771255c0753",
            "28edb661897e4e7dbea2e95d42b39f9a"
          ]
        },
        "id": "1S7n_uY08ABl",
        "outputId": "687b6b76-7ef2-4b4c-bc26-8472bf2cc1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  _C._set_float32_matmul_precision(precision)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "LOCAL-ONLY (NO AGGREGATION) + GA-FELCM + PVTv2-B2 (FUSION) | TEST METRICS ONLY\n",
            "============================================================================================\n",
            "DEVICE: cpu | torch=2.9.0+cpu\n",
            "============================================================================================\n",
            "Downloading datasets...\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130M/130M [00:00<00:00, 173MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/orvile/pmram-bangladeshi-brain-cancer-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161M/161M [00:01<00:00, 133MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training local model for client_0 (ds1)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/101M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e1e5e21390c4cce86bedd801fb2c5e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training local model for client_1 (ds1)...\n",
            "\n",
            "Training local model for client_2 (ds1)...\n",
            "\n",
            "Training local model for client_3 (ds2)...\n",
            "\n",
            "Training local model for client_4 (ds2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training local model for client_5 (ds2)...\n",
            "\n",
            "Final TEST metrics (requested format):\n",
            "                    setting split         dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Local-only (no aggregation)  TEST    ds1_client_0 0.736842         0.793881      0.740198  0.678583            0.800831         0.736842     0.681907  0.849699           0.933505 0.864920    21.507455\n",
            "Local-only (no aggregation)  TEST    ds1_client_1 0.706667         0.816667      0.735726  0.706815            0.817778         0.706667     0.683605  0.922017           0.941527 0.915738    21.081559\n",
            "Local-only (no aggregation)  TEST    ds1_client_2 0.626667         0.689286      0.547269  0.466917            0.668762         0.626667     0.520929  1.090790           0.800643 1.145110    21.619763\n",
            "Local-only (no aggregation)  TEST    ds2_client_3 0.548295         0.682418      0.538990  0.461983            0.713061         0.548295     0.472264  0.922978           0.883671 0.910059   101.525707\n",
            "Local-only (no aggregation)  TEST    ds2_client_4 0.747159         0.838117      0.723955  0.648943            0.847672         0.747159     0.677455  0.940765           0.892922 0.921582   100.406385\n",
            "Local-only (no aggregation)  TEST    ds2_client_5 0.732194         0.779710      0.755783  0.663073            0.803891         0.732194     0.658735  0.986163           0.889305 0.963914    98.280948\n",
            "Local-only (no aggregation)  TEST        ds1_mean 0.690265         0.766732      0.674689  0.617709            0.762627         0.690265     0.629048  0.953706           0.892076 0.974768    21.403388\n",
            "Local-only (no aggregation)  TEST        ds2_mean 0.675829         0.766736      0.672831  0.591265            0.788193         0.675829     0.602765  0.949934           0.888632 0.931821   100.072710\n",
            "Local-only (no aggregation)  TEST global_weighted 0.678376         0.766735      0.673159  0.595930            0.783682         0.678376     0.607402  0.950600           0.889239 0.939398    86.193501\n",
            "\n",
            "Saved: /content/outputs/LOCAL_ONLY_TEST_METRICS.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import subprocess\n",
        "import hashlib\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    log_loss,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "\n",
        "def pip_install(pkg: str):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + Device\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"=\" * 92)\n",
        "print(\"LOCAL-ONLY (NO AGGREGATION) + GA-FELCM + PVTv2-B2 (FUSION) | TEST METRICS ONLY\")\n",
        "print(\"=\" * 92)\n",
        "print(f\"DEVICE: {DEVICE} | torch={torch.__version__}\")\n",
        "print(\"=\" * 92)\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"local_epochs\": 4,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"cond_dim\": 128,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "CSV_PATH = os.path.join(OUTDIR, \"LOCAL_ONLY_TEST_METRICS.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "# -------------------------\n",
        "# Dataset discovery\n",
        "# -------------------------\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "label2id = {l: i for i, l in enumerate(labels)}\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    dfm[\"y\"] = dfm[\"label\"].map(label2id).astype(int)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start:start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Data loading\n",
        "# -------------------------\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "TRAIN_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None, source_id=0, client_id=0):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "        self.source_id = int(source_id)\n",
        "        self.client_id = int(client_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        x = self.tfms(load_rgb(row[\"path\"]))\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"], self.source_id, self.client_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(sample_weights), len(sample_weights), replacement=True)\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None, source_id=0, client_id=0):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms, source_id=source_id, client_id=client_id)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Preprocessor + model\n",
        "# -------------------------\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        c_map = lap / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * c_map)\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(nn.Conv2d(c, out_dim, 1, bias=False), nn.GroupNorm(8, out_dim), nn.GELU())\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, 3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class PVTv2B2_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128, num_clients=6):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\"pvt_v2_b2\", pretrained=pretrained, features_only=True, out_indices=(0, 1, 2, 3))\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "        self.theta_mlp = nn.Sequential(nn.Linear(7, cond_dim), nn.GELU(), nn.Linear(cond_dim, cond_dim))\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.client_emb = nn.Embedding(num_clients, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id, client_id):\n",
        "        return self.cond_norm(self.theta_mlp(theta_vec) + self.source_emb(source_id) + self.client_emb(client_id))\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id, client_id)\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "        f0, f1 = self.fuser(feats0), self.fuser(feats1)\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f = (1 - g1) * f0 + g1 * f1\n",
        "        return self.classifier(f)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor([\n",
        "            preproc_module.gamma,\n",
        "            preproc_module.alpha,\n",
        "            preproc_module.beta,\n",
        "            preproc_module.tau,\n",
        "            float(preproc_module.blur_k) / 7.0,\n",
        "            preproc_module.sharpen,\n",
        "            preproc_module.denoise,\n",
        "        ], device=DEVICE, dtype=torch.float32)\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "    centroids, within_vars, sizes = [], [], []\n",
        "    for c in classes:\n",
        "        e = emb[y == c]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else 1e-6\n",
        "    return float(between / (within + 1e-6))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "    x_p = pre(x)\n",
        "\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, _, sh, dn = theta\n",
        "    cost = (0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn)\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, dl_for_eval):\n",
        "    try:\n",
        "        bx, by, *_ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    pop = [random_theta() for _ in range(CFG[\"ga_pop\"])]\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1]\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "\n",
        "    for x, y, _, source_id, client_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "        client_id = client_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        theta_vec = preproc_theta_vec(preproc_module, x.size(0))\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.cpu().numpy())\n",
        "        all_p.append(probs.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(all_y) if all_y else np.array([])\n",
        "    p_pred = np.concatenate(all_p) if all_p else np.array([])\n",
        "    if len(y_true) == 0:\n",
        "        return {k: np.nan for k in [\n",
        "            \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "            \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "        ]}\n",
        "\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "    out = {\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        out[\"auc_roc_macro_ovr\"] = np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Downloading datasets...\")\n",
        "    ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "    ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "    ds1_root = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "    ds2_root = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "    if ds1_root is None or ds2_root is None:\n",
        "        raise RuntimeError(\"Could not discover dataset roots\")\n",
        "\n",
        "    df1 = build_df_from_root(ds1_root, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\")\n",
        "    df2 = build_df_from_root(ds2_root, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\")\n",
        "\n",
        "    train1, _, test1 = split_dataset(df1)\n",
        "    train2, _, test2 = split_dataset(df2)\n",
        "\n",
        "    n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "    client_idx_ds1 = make_clients_non_iid(train1, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "    client_idx_ds2 = make_clients_non_iid(train2, n_per_ds, NUM_CLASSES, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "    client_splits = []\n",
        "    for k in range(n_per_ds):\n",
        "        tr, tune, _ = robust_client_splits(train1, client_idx_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "        client_splits.append((\"ds1\", k, k, tr, tune))\n",
        "    for k in range(n_per_ds):\n",
        "        tr, tune, _ = robust_client_splits(train2, client_idx_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "        client_splits.append((\"ds2\", k, n_per_ds + k, tr, tune))\n",
        "\n",
        "    client_test_splits = []\n",
        "    for ds_name, test_df, gid_base in [(\"ds1\", test1, 0), (\"ds2\", test2, n_per_ds)]:\n",
        "        idxs = list(range(len(test_df)))\n",
        "        random.shuffle(idxs)\n",
        "        split = np.array_split(idxs, n_per_ds)\n",
        "        for k in range(n_per_ds):\n",
        "            client_test_splits.append((ds_name, k, gid_base + k, split[k].tolist()))\n",
        "\n",
        "    counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "    counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "    counts = counts1 + counts2\n",
        "    w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "    w = w / max(1e-6, w.mean())\n",
        "    class_w = torch.tensor(w, device=DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_w, label_smoothing=CFG[\"label_smoothing\"])\n",
        "    scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "    rows = []\n",
        "    ds_accumulator: Dict[str, List[Tuple[dict, int]]] = {\"ds1\": [], \"ds2\": []}\n",
        "\n",
        "    for ds_name, _, gid, tr_idx, tune_idx in client_splits:\n",
        "        print(f\"\\nTraining local model for client_{gid} ({ds_name})...\")\n",
        "        df_train = train1 if ds_name == \"ds1\" else train2\n",
        "        df_test = test1 if ds_name == \"ds1\" else test2\n",
        "        source_id = 0 if ds_name == \"ds1\" else 1\n",
        "\n",
        "        sampler = make_weighted_sampler(df_train, tr_idx, NUM_CLASSES)\n",
        "        tr_loader = make_loader(df_train, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler, source_id=source_id, client_id=gid)\n",
        "        tune_loader = make_loader(df_train, tune_idx if len(tune_idx) else tr_idx[: max(1, len(tr_idx))], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True, source_id=source_id, client_id=gid)\n",
        "\n",
        "        test_idx = next(x[3] for x in client_test_splits if x[2] == gid)\n",
        "        test_loader = make_loader(df_test, test_idx, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False, source_id=source_id, client_id=gid)\n",
        "\n",
        "        model = PVTv2B2_MultiScale(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            pretrained=True,\n",
        "            head_dropout=CFG[\"head_dropout\"],\n",
        "            cond_dim=CFG[\"cond_dim\"],\n",
        "            num_clients=CFG[\"clients_total\"],\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        backbone_frozen = model.backbone.eval()\n",
        "        for p in backbone_frozen.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        theta = run_ga_for_client(backbone_frozen, tune_loader) if (CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]) else None\n",
        "        pre = theta_to_module(theta).to(DEVICE) if theta is not None else nn.Identity().to(DEVICE)\n",
        "\n",
        "        params = [p for p in model.parameters() if p.requires_grad]\n",
        "        opt = torch.optim.AdamW(params, lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "        total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "        warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "        scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "        for _ in range(CFG[\"local_epochs\"]):\n",
        "            train_one_epoch(model, tr_loader, opt, pre, criterion, scheduler=scheduler, scaler=scaler)\n",
        "\n",
        "        met = evaluate_full(model, test_loader, pre)\n",
        "        row = {\n",
        "            \"setting\": \"Local-only (no aggregation)\",\n",
        "            \"split\": \"TEST\",\n",
        "            \"dataset\": f\"{ds_name}_client_{gid}\",\n",
        "            **{k: met.get(k, np.nan) for k in [\n",
        "                \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "                \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "                \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "            ]},\n",
        "        }\n",
        "        rows.append(row)\n",
        "        ds_accumulator[ds_name].append((met, len(test_loader.dataset)))\n",
        "\n",
        "    def weighted_avg(parts):\n",
        "        if not parts:\n",
        "            return {}\n",
        "        total = sum(w for _, w in parts)\n",
        "        keys = [\n",
        "            \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "            \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "            \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "        ]\n",
        "        out = {}\n",
        "        for k in keys:\n",
        "            vals, ws = [], []\n",
        "            for m, w in parts:\n",
        "                vals.append(m.get(k, np.nan))\n",
        "                ws.append(w)\n",
        "            out[k] = float(np.average(vals, weights=ws))\n",
        "        return out\n",
        "\n",
        "    ds1_agg = weighted_avg(ds_accumulator[\"ds1\"])\n",
        "    ds2_agg = weighted_avg(ds_accumulator[\"ds2\"])\n",
        "    global_agg = weighted_avg(ds_accumulator[\"ds1\"] + ds_accumulator[\"ds2\"])\n",
        "\n",
        "    for dname, m in [(\"ds1_mean\", ds1_agg), (\"ds2_mean\", ds2_agg), (\"global_weighted\", global_agg)]:\n",
        "        rows.append({\n",
        "            \"setting\": \"Local-only (no aggregation)\",\n",
        "            \"split\": \"TEST\",\n",
        "            \"dataset\": dname,\n",
        "            **{k: m.get(k, np.nan) for k in [\n",
        "                \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "                \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
        "                \"log_loss\", \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "            ]},\n",
        "        })\n",
        "\n",
        "    out_df = pd.DataFrame(rows, columns=[\n",
        "        \"setting\", \"split\", \"dataset\", \"acc\", \"precision_macro\", \"recall_macro\", \"f1_macro\",\n",
        "        \"precision_weighted\", \"recall_weighted\", \"f1_weighted\", \"log_loss\",\n",
        "        \"auc_roc_macro_ovr\", \"loss_ce\", \"eval_time_s\",\n",
        "    ])\n",
        "\n",
        "    print(\"\\nFinal TEST metrics (requested format):\")\n",
        "    print(out_df.to_string(index=False))\n",
        "\n",
        "    out_df.to_csv(CSV_PATH, index=False)\n",
        "    print(f\"\\nSaved: {CSV_PATH}\")\n"
      ]
    }
  ]
}