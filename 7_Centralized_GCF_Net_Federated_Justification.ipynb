{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5bf288624674c28b7d4fa5b1b121350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8881b5569e51480fa11a0efb01f03d73",
              "IPY_MODEL_075b2cefba28469e8b058f541cbb81d5",
              "IPY_MODEL_46a48334bcdc4f0790ef57b6b9cb1ea6"
            ],
            "layout": "IPY_MODEL_63f5b8a8e60545f0abc513d1dc1fa949"
          }
        },
        "8881b5569e51480fa11a0efb01f03d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e5b5235e2934589a67166bc8a9b9fab",
            "placeholder": "​",
            "style": "IPY_MODEL_48bb2ad29f5f470fa718bb896134275e",
            "value": "model.safetensors: 100%"
          }
        },
        "075b2cefba28469e8b058f541cbb81d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_143aa80614b840d085a62cde4e16c7ad",
            "max": 101484732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbbc059192524eecb24cf5db4268385d",
            "value": 101484732
          }
        },
        "46a48334bcdc4f0790ef57b6b9cb1ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da931c0d2504b6e8bea297c6a9d0844",
            "placeholder": "​",
            "style": "IPY_MODEL_6d4eac812ef24d8b91b9f5c84cf30f7c",
            "value": " 101M/101M [00:03&lt;00:00, 54.9MB/s]"
          }
        },
        "63f5b8a8e60545f0abc513d1dc1fa949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5b5235e2934589a67166bc8a9b9fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48bb2ad29f5f470fa718bb896134275e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "143aa80614b840d085a62cde4e16c7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbc059192524eecb24cf5db4268385d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6da931c0d2504b6e8bea297c6a9d0844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4eac812ef24d8b91b9f5c84cf30f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**“Centralized GCF-Net”** means: you train **the same FedGCF-Net architecture/process**, but **NOT federated**.\n",
        "\n",
        "### What you do in centralized GCF-Net\n",
        "\n",
        "* **Merge the training data** (DS1 + DS2 train splits) into **one single dataset**\n",
        "* Train **one model on one machine** (standard training)\n",
        "* Validate/test on DS1 and DS2 test splits (same as you do now)\n",
        "\n",
        "### What you do NOT do\n",
        "\n",
        "* No clients\n",
        "* No FedAvg aggregation\n",
        "* No FedProx term (unless you keep it, but usually you turn it off)\n",
        "* No per-client conditioning (you can set `client_id=0` for all, or remove client embedding)\n",
        "\n",
        "### Why it’s useful\n",
        "\n",
        "* It’s the **upper bound** when data sharing is allowed.\n",
        "* It shows: “If we could centralize data\n"
      ],
      "metadata": {
        "id": "cJoQZrJVNeaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "e5bf288624674c28b7d4fa5b1b121350",
            "8881b5569e51480fa11a0efb01f03d73",
            "075b2cefba28469e8b058f541cbb81d5",
            "46a48334bcdc4f0790ef57b6b9cb1ea6",
            "63f5b8a8e60545f0abc513d1dc1fa949",
            "4e5b5235e2934589a67166bc8a9b9fab",
            "48bb2ad29f5f470fa718bb896134275e",
            "143aa80614b840d085a62cde4e16c7ad",
            "dbbc059192524eecb24cf5db4268385d",
            "6da931c0d2504b6e8bea297c6a9d0844",
            "6d4eac812ef24d8b91b9f5c84cf30f7c"
          ]
        },
        "id": "IJAshV5E5SGo",
        "outputId": "7370a679-685b-4f86-af1b-6a53dc5106c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130M/130M [00:06<00:00, 19.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/orvile/pmram-bangladeshi-brain-cancer-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161M/161M [00:09<00:00, 17.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/101M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5bf288624674c28b7d4fa5b1b121350"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            setting split         dataset      acc  precision_macro  recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr  loss_ce  eval_time_s\n",
            "Centralized GCF-Net  TEST             ds1 0.973451         0.973441      0.973360  0.973207            0.973908         0.973451     0.973488  0.172691           0.993911 0.164041     6.403807\n",
            "Centralized GCF-Net  TEST             ds2 0.964929         0.963347      0.963957  0.963530            0.965235         0.964929     0.964966  0.175786           0.995404 0.175774    18.914482\n",
            "Centralized GCF-Net  TEST global_weighted 0.966432         0.965128      0.965616  0.965238            0.966766         0.966432     0.966469  0.175240           0.995140 0.173704    16.707290\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import sys\n",
        "import subprocess\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    log_loss,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "\n",
        "def pip_install(pkg: str):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "CFG = {\n",
        "    # centralized runtime defaults (faster than FL while keeping architecture/process)\n",
        "    \"epochs\": 6,\n",
        "    \"early_stop_patience\": 2,\n",
        "    \"batch_size\": 32 if torch.cuda.is_available() else 8,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 128,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "\n",
        "    # mimic prior split style\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "\n",
        "    # preprocessing/GA\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 6,\n",
        "    \"ga_gens\": 3,\n",
        "    \"ga_elites\": 2,\n",
        "    \"ga_sample_size\": 256,\n",
        "\n",
        "    # model/training speed\n",
        "    \"backbone_name\": \"pvt_v2_b2\",\n",
        "    \"head_dropout\": 0.3,\n",
        "    \"cond_dim\": 128,\n",
        "    \"freeze_backbone\": True,\n",
        "    \"unfreeze_after_epoch\": 3,\n",
        "    \"unfreeze_tail_frac\": 0.15,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "}\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "REQ1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "REQ2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "LABELS = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "LABEL2ID = {l: i for i, l in enumerate(LABELS)}\n",
        "NUM_CLASSES = len(LABELS)\n",
        "\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(path):\n",
        "        p = path.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in p:\n",
        "                sc += 7\n",
        "            if os.path.basename(path).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in p or \"\\\\raw\\\\\" in p:\n",
        "                sc += 3\n",
        "            if \"augmented\" in p:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(path)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        for path in list_images_under_class_root(ds_root, c):\n",
        "            rows.append({\"path\": path, \"label\": lab, \"source\": source_name})\n",
        "    df = pd.DataFrame(rows).dropna().drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    df[\"label\"] = df[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df = df[df[\"label\"].isin(set(LABELS))].reset_index(drop=True)\n",
        "    df[\"y\"] = df[\"label\"].map(LABEL2ID).astype(int)\n",
        "    return df\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "TRAIN_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, tfms=None):\n",
        "        self.df = frame.reset_index(drop=True)\n",
        "        self.tfms = tfms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        source_id = 0 if row[\"source\"] == \"ds1_raw\" else 1\n",
        "        return x, y, source_id\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, num_classes):\n",
        "    ys = frame[\"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(torch.DoubleTensor(sample_weights), len(sample_weights), replacement=True)\n",
        "\n",
        "\n",
        "def make_loader(frame, bs, tfms, shuffle=False, sampler=None):\n",
        "    ds = MRIDataset(frame, tfms=tfms)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        b, c, _, _ = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = ((x - mu) / sd).clamp(-self.tau, self.tau)\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap).abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(lap, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        c_map = lap / (blur + eps)\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * c_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            out = []\n",
        "            for i in range(c):\n",
        "                x_c = x2[:, i : i + 1]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                out.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(out, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        return ((x2 - mn) / (mx - mn + eps)).clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        return self.pool(x.flatten(2).transpose(1, 2))\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class PVTv2B2_MultiScale(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            CFG[\"backbone_name\"],\n",
        "            pretrained=pretrained,\n",
        "            features_only=True,\n",
        "            out_indices=(0, 1, 2, 3),\n",
        "        )\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        # centralized: source + theta conditioning only (no client conditioning)\n",
        "        self.theta_mlp = nn.Sequential(\n",
        "            nn.Linear(7, cond_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cond_dim, cond_dim),\n",
        "        )\n",
        "        self.source_emb = nn.Embedding(2, cond_dim)\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _cond_vec(self, theta_vec, source_id):\n",
        "        return self.cond_norm(self.theta_mlp(theta_vec) + self.source_emb(source_id))\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id):\n",
        "        cond = self._cond_vec(theta_vec, source_id)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(preproc_module, batch_size):\n",
        "    if hasattr(preproc_module, \"gamma\"):\n",
        "        theta = torch.tensor(\n",
        "            [\n",
        "                preproc_module.gamma,\n",
        "                preproc_module.alpha,\n",
        "                preproc_module.beta,\n",
        "                preproc_module.tau,\n",
        "                float(preproc_module.blur_k) / 7.0,\n",
        "                preproc_module.sharpen,\n",
        "                preproc_module.denoise,\n",
        "            ],\n",
        "            device=DEVICE,\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "    else:\n",
        "        theta = torch.zeros(7, device=DEVICE, dtype=torch.float32)\n",
        "    return theta.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "\n",
        "def set_trainable_for_epoch(model, epoch):\n",
        "    if not CFG[\"freeze_backbone\"]:\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = True\n",
        "        return\n",
        "\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    if epoch >= CFG[\"unfreeze_after_epoch\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    y = y.long()\n",
        "    classes = torch.unique(y)\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids, within_vars, sizes = [], [], []\n",
        "    for c in classes:\n",
        "        e = emb[y == c]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        centroids.append(mu)\n",
        "        within_vars.append((e - mu).pow(2).sum(dim=1).mean().item())\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    gmean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - gmean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    emb = backbone_frozen((x_p - IMAGENET_MEAN) / IMAGENET_STD)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "    sep = enhanced_separability_score(emb, y)\n",
        "\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    cost = 0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga(backbone_frozen, dl_for_eval):\n",
        "    try:\n",
        "        bx, by, _ = next(iter(dl_for_eval))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    pop = [random_theta() for _ in range(CFG[\"ga_pop\"])]\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = sorted([(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop], key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1]\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "    for x, y, source_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            logits = model(x_raw_n, x_fel_n, preproc_theta_vec(preproc_module, x.size(0)), source_id)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, preproc_module):\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "    t0 = time.time()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    for x, y, source_id in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "        source_id = source_id.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        logits = model(x_raw_n, x_fel_n, preproc_theta_vec(preproc_module, x.size(0)), source_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "        all_loss.append(float(F.cross_entropy(logits, y).item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    return {\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(NUM_CLASSES)))),\n",
        "        \"auc_roc_macro_ovr\": float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\")),\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "\n",
        "\n",
        "def weighted_merge(metrics_a, n_a, metrics_b, n_b):\n",
        "    out = {}\n",
        "    total = n_a + n_b\n",
        "    for k in metrics_a.keys():\n",
        "        out[k] = float((metrics_a[k] * n_a + metrics_b[k] * n_b) / total)\n",
        "    return out\n",
        "\n",
        "\n",
        "def main():\n",
        "    ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "    ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "    ds1_root = find_root_with_required_class_dirs(ds1_path, REQ1, prefer_raw=True)\n",
        "    ds2_root = find_root_with_required_class_dirs(ds2_path, REQ2, prefer_raw=False)\n",
        "    if ds1_root is None or ds2_root is None:\n",
        "        raise RuntimeError(\"Failed to locate dataset roots.\")\n",
        "\n",
        "    df1 = build_df_from_root(ds1_root, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\")\n",
        "    df2 = build_df_from_root(ds2_root, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\")\n",
        "\n",
        "    train1, val1, test1 = split_dataset(df1)\n",
        "    train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "    train_all = pd.concat([train1, train2], axis=0).reset_index(drop=True)\n",
        "    val_all = pd.concat([val1, val2], axis=0).reset_index(drop=True)\n",
        "\n",
        "    sampler = make_weighted_sampler(train_all, NUM_CLASSES)\n",
        "    train_loader = make_loader(train_all, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler)\n",
        "    val_loader = make_loader(val_all, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False)\n",
        "    test1_loader = make_loader(test1, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False)\n",
        "    test2_loader = make_loader(test2, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False)\n",
        "\n",
        "    ga_frame = train_all.sample(min(CFG[\"ga_sample_size\"], len(train_all)), random_state=SEED).reset_index(drop=True)\n",
        "    ga_loader = make_loader(ga_frame, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False)\n",
        "\n",
        "    model = PVTv2B2_MultiScale(\n",
        "        num_classes=NUM_CLASSES,\n",
        "        pretrained=True,\n",
        "        head_dropout=CFG[\"head_dropout\"],\n",
        "        cond_dim=CFG[\"cond_dim\"],\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # class-balanced loss\n",
        "    counts = train_all[\"y\"].value_counts().sort_index().reindex(range(NUM_CLASSES), fill_value=0).values\n",
        "    w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "    w = w / max(1e-6, w.mean())\n",
        "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "\n",
        "    preproc = nn.Identity().to(DEVICE)\n",
        "    if CFG[\"use_preprocessing\"]:\n",
        "        if CFG[\"use_ga\"]:\n",
        "            backbone_frozen = model.backbone.eval()\n",
        "            for p in backbone_frozen.parameters():\n",
        "                p.requires_grad = False\n",
        "            best_theta = run_ga(backbone_frozen, ga_loader)\n",
        "            preproc = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "        else:\n",
        "            preproc = EnhancedFELCM().to(DEVICE)\n",
        "\n",
        "    scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "    best_state = None\n",
        "    best_val_f1 = -1.0\n",
        "    stale_epochs = 0\n",
        "\n",
        "    for epoch in range(1, CFG[\"epochs\"] + 1):\n",
        "        set_trainable_for_epoch(model, epoch)\n",
        "        optimizer = make_optimizer(model)\n",
        "        total_steps = max(1, len(train_loader))\n",
        "        warmup_steps = max(1, int(len(train_loader) * CFG[\"warmup_epochs\"]))\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\n",
        "        train_one_epoch(model, train_loader, optimizer, preproc, criterion, scheduler=scheduler, scaler=scaler)\n",
        "\n",
        "        val_metrics = evaluate(model, val_loader, preproc)\n",
        "        if val_metrics[\"f1_macro\"] > best_val_f1:\n",
        "            best_val_f1 = val_metrics[\"f1_macro\"]\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            stale_epochs = 0\n",
        "        else:\n",
        "            stale_epochs += 1\n",
        "            if stale_epochs >= CFG[\"early_stop_patience\"]:\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()})\n",
        "\n",
        "    test_ds1 = evaluate(model, test1_loader, preproc)\n",
        "    test_ds2 = evaluate(model, test2_loader, preproc)\n",
        "    test_global = weighted_merge(test_ds1, len(test1), test_ds2, len(test2))\n",
        "\n",
        "    cols = [\n",
        "        \"setting\",\n",
        "        \"split\",\n",
        "        \"dataset\",\n",
        "        \"acc\",\n",
        "        \"precision_macro\",\n",
        "        \"recall_macro\",\n",
        "        \"f1_macro\",\n",
        "        \"precision_weighted\",\n",
        "        \"recall_weighted\",\n",
        "        \"f1_weighted\",\n",
        "        \"log_loss\",\n",
        "        \"auc_roc_macro_ovr\",\n",
        "        \"loss_ce\",\n",
        "        \"eval_time_s\",\n",
        "    ]\n",
        "    out = pd.DataFrame([\n",
        "        {\"setting\": \"Centralized GCF-Net\", \"split\": \"TEST\", \"dataset\": \"ds1\", **test_ds1},\n",
        "        {\"setting\": \"Centralized GCF-Net\", \"split\": \"TEST\", \"dataset\": \"ds2\", **test_ds2},\n",
        "        {\"setting\": \"Centralized GCF-Net\", \"split\": \"TEST\", \"dataset\": \"global_weighted\", **test_global},\n",
        "    ])[cols]\n",
        "\n",
        "    print(out.to_string(index=False))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}