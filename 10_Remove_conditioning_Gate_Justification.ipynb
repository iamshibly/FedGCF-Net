{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c582da80c70d4fbbac70edb65bdd8f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5bb35a0237a4bfeae54826fd5562bfe",
              "IPY_MODEL_c57ce68f3c0e42cb81e1cb5c59f2f6e2",
              "IPY_MODEL_f4ee01e11146443a8364b6a332fb3818"
            ],
            "layout": "IPY_MODEL_c50d5d6883c24d06a9e161b9fe01973a"
          }
        },
        "e5bb35a0237a4bfeae54826fd5562bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e599a5d3d86c4a2a80d5e527bfc7bd2f",
            "placeholder": "​",
            "style": "IPY_MODEL_15901f9f9b934c5f9eee1a67115a6d5a",
            "value": "model.safetensors: 100%"
          }
        },
        "c57ce68f3c0e42cb81e1cb5c59f2f6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d40a85b54c041d2a36bc600bcea1c1f",
            "max": 101484732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f4174577ac24cbcab28807e3606f9fc",
            "value": 101484732
          }
        },
        "f4ee01e11146443a8364b6a332fb3818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eabf3077c41408397871bcc793f061b",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f6c7b125194de39ce1c0cfaf370412",
            "value": " 101M/101M [00:01&lt;00:00, 113MB/s]"
          }
        },
        "c50d5d6883c24d06a9e161b9fe01973a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e599a5d3d86c4a2a80d5e527bfc7bd2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15901f9f9b934c5f9eee1a67115a6d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d40a85b54c041d2a36bc600bcea1c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4174577ac24cbcab28807e3606f9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eabf3077c41408397871bcc793f061b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f6c7b125194de39ce1c0cfaf370412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Remove conditioning (prove θ/source/client conditioning matters)\n",
        "\n",
        "Keep gates, but remove the conditioning signal by:\n",
        "\n",
        "setting theta_vec = zeros\n",
        "\n",
        "setting source_id = 0 for all\n",
        "\n",
        "setting client_id = 0 for all\n",
        "(or skip embeddings)\n",
        "If performance drops → gates are truly conditioning-aware, not generic."
      ],
      "metadata": {
        "id": "a6hsQtgiNLvt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801,
          "referenced_widgets": [
            "c582da80c70d4fbbac70edb65bdd8f48",
            "e5bb35a0237a4bfeae54826fd5562bfe",
            "c57ce68f3c0e42cb81e1cb5c59f2f6e2",
            "f4ee01e11146443a8364b6a332fb3818",
            "c50d5d6883c24d06a9e161b9fe01973a",
            "e599a5d3d86c4a2a80d5e527bfc7bd2f",
            "15901f9f9b934c5f9eee1a67115a6d5a",
            "4d40a85b54c041d2a36bc600bcea1c1f",
            "1f4174577ac24cbcab28807e3606f9fc",
            "7eabf3077c41408397871bcc793f061b",
            "f6f6c7b125194de39ce1c0cfaf370412"
          ]
        },
        "id": "b2gNTEsJNJyk",
        "outputId": "201341be-4669-4429-a93c-6194c62dc419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130M/130M [00:06<00:00, 21.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.3).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/orvile/pmram-bangladeshi-brain-cancer-mri-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161M/161M [00:00<00:00, 177MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/101M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c582da80c70d4fbbac70edb65bdd8f48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             setting split           dataset  \\\n",
            "0  No conditioning (theta/source/client forced to...   VAL  ds1+ds2 weighted   \n",
            "1  No conditioning (theta/source/client forced to...  TEST               ds1   \n",
            "2  No conditioning (theta/source/client forced to...  TEST               ds2   \n",
            "3  No conditioning (theta/source/client forced to...  TEST   global weighted   \n",
            "\n",
            "        acc  precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
            "0  0.930490         0.783962      0.961703  0.795308            0.974714   \n",
            "1  0.915929         0.922366      0.914262  0.909991            0.925800   \n",
            "2  0.944076         0.945168      0.939752  0.937784            0.949139   \n",
            "3  0.939110         0.941145      0.935255  0.932880            0.945021   \n",
            "\n",
            "   recall_weighted  f1_weighted  log_loss  auc_roc_macro_ovr   loss_ce  \\\n",
            "0         0.930490     0.946291  0.253498                NaN  0.243204   \n",
            "1         0.915929     0.912756  0.319914           0.976933  0.313734   \n",
            "2         0.944076     0.942347  0.208666           0.991357  0.209560   \n",
            "3         0.939110     0.937126  0.228293           0.988812  0.227939   \n",
            "\n",
            "   eval_time_s  \n",
            "0     2.895505  \n",
            "1     2.546499  \n",
            "2     7.236321  \n",
            "3     6.408921  \n",
            "Saved: /content/outputs/VAL_TEST_METRICS_ONLY_NO_CONDITIONING.csv\n",
            "Saved: /content/outputs/FL_GAFELCM_PVTv2B2_FUSION_NO_CONDITIONING.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import sys\n",
        "import subprocess\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    log_loss,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Utilities\n",
        "# ============================================================\n",
        "\n",
        "def pip_install(pkg: str):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", pkg])\n",
        "\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except Exception:\n",
        "    pip_install(\"timm\")\n",
        "    import timm\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "except Exception:\n",
        "    pip_install(\"kagglehub\")\n",
        "    import kagglehub\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "\n",
        "CFG = {\n",
        "    \"clients_per_dataset\": 3,\n",
        "    \"clients_total\": 6,\n",
        "    \"rounds\": 12,\n",
        "    \"local_epochs\": 2,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"warmup_epochs\": 1,\n",
        "    \"label_smoothing\": 0.08,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"fedprox_mu\": 0.01,\n",
        "    \"img_size\": 224 if torch.cuda.is_available() else 160,\n",
        "    \"batch_size\": 20 if torch.cuda.is_available() else 10,\n",
        "    \"num_workers\": 2 if torch.cuda.is_available() else 0,\n",
        "    \"global_val_frac\": 0.15,\n",
        "    \"test_frac\": 0.15,\n",
        "    \"client_val_frac\": 0.12,\n",
        "    \"client_tune_frac\": 0.12,\n",
        "    \"min_per_class_per_client\": 5,\n",
        "    \"dirichlet_alpha\": 0.35,\n",
        "    \"use_preprocessing\": True,\n",
        "    \"use_ga\": True,\n",
        "    \"ga_pop\": 10,\n",
        "    \"ga_gens\": 5,\n",
        "    \"ga_elites\": 3,\n",
        "    \"elite_pool_max\": 18,\n",
        "    \"unfreeze_after_round\": 3,\n",
        "    \"unfreeze_lr_mult\": 0.10,\n",
        "    \"unfreeze_tail_frac\": 0.17,\n",
        "}\n",
        "\n",
        "OUTDIR = \"/content/outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"FL_GAFELCM_PVTv2B2_FUSION_NO_CONDITIONING.pth\")\n",
        "CSV_PATH = os.path.join(OUTDIR, \"VAL_TEST_METRICS_ONLY_NO_CONDITIONING.csv\")\n",
        "\n",
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\")\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(1, 3, 1, 1)\n",
        "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(1, 3, 1, 1)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Dataset\n",
        "# ============================================================\n",
        "\n",
        "def norm_label(name: str):\n",
        "    s = str(name).strip().lower()\n",
        "    if \"glioma\" in s:\n",
        "        return \"glioma\"\n",
        "    if \"meningioma\" in s:\n",
        "        return \"meningioma\"\n",
        "    if \"pituitary\" in s:\n",
        "        return \"pituitary\"\n",
        "    if \"normal\" in s or \"no_tumor\" in s or \"no tumor\" in s or \"notumor\" in s:\n",
        "        return \"notumor\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_root_with_required_class_dirs(base_dir, required_set, prefer_raw=True):\n",
        "    candidates = []\n",
        "    for root, dirs, _ in os.walk(base_dir):\n",
        "        if required_set.issubset(set(dirs)):\n",
        "            candidates.append(root)\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    def score(p):\n",
        "        pl = p.lower()\n",
        "        sc = 0\n",
        "        if prefer_raw:\n",
        "            if \"raw data\" in pl:\n",
        "                sc += 7\n",
        "            if os.path.basename(p).lower() == \"raw\":\n",
        "                sc += 7\n",
        "            if \"/raw/\" in pl or \"\\\\raw\\\\\" in pl:\n",
        "                sc += 3\n",
        "            if \"augmented\" in pl:\n",
        "                sc -= 20\n",
        "        sc -= 0.0001 * len(p)\n",
        "        return sc\n",
        "\n",
        "    return max(candidates, key=score)\n",
        "\n",
        "\n",
        "def list_images_under_class_root(class_root, class_dir_name):\n",
        "    class_dir = os.path.join(class_root, class_dir_name)\n",
        "    out = []\n",
        "    for r, _, files in os.walk(class_dir):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith(IMG_EXTS):\n",
        "                out.append(os.path.join(r, fn))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_df_from_root(ds_root, class_dirs, source_name):\n",
        "    rows = []\n",
        "    for c in class_dirs:\n",
        "        lab = norm_label(c)\n",
        "        imgs = list_images_under_class_root(ds_root, c)\n",
        "        for p in imgs:\n",
        "            rows.append({\"path\": p, \"label\": lab, \"source\": source_name})\n",
        "    dfm = pd.DataFrame(rows).dropna().reset_index(drop=True)\n",
        "    dfm = dfm.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
        "    dfm[\"filename\"] = dfm[\"path\"].apply(os.path.basename)\n",
        "    return dfm\n",
        "\n",
        "\n",
        "def enforce_labels(df_, labels, label2id):\n",
        "    df_ = df_.copy()\n",
        "    df_[\"label\"] = df_[\"label\"].astype(str).str.strip().str.lower()\n",
        "    df_ = df_[df_[\"label\"].isin(set(labels))].reset_index(drop=True)\n",
        "    df_[\"y\"] = df_[\"label\"].map(label2id).astype(int)\n",
        "    return df_\n",
        "\n",
        "\n",
        "def split_dataset(df_):\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df_,\n",
        "        test_size=(CFG[\"global_val_frac\"] + CFG[\"test_frac\"]),\n",
        "        stratify=df_[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    val_rel = CFG[\"global_val_frac\"] / (CFG[\"global_val_frac\"] + CFG[\"test_frac\"])\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=(1 - val_rel),\n",
        "        stratify=temp_df[\"y\"],\n",
        "        random_state=SEED,\n",
        "    )\n",
        "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def make_clients_non_iid(train_df, n_clients, num_classes, min_per_class=5, alpha=0.35):\n",
        "    y = train_df[\"y\"].values\n",
        "    idx_by_class = {c: np.where(y == c)[0].tolist() for c in range(num_classes)}\n",
        "    for c in idx_by_class:\n",
        "        random.shuffle(idx_by_class[c])\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        feasible = min(min_per_class, max(1, len(idxs) // n_clients))\n",
        "        for k in range(n_clients):\n",
        "            take = idxs[:feasible]\n",
        "            idxs = idxs[feasible:]\n",
        "            client_indices[k].extend(take)\n",
        "        idx_by_class[c] = idxs\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        idxs = idx_by_class[c]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        props = np.random.dirichlet([alpha] * n_clients)\n",
        "        counts = (props * len(idxs)).astype(int)\n",
        "        diff = len(idxs) - counts.sum()\n",
        "        counts[np.argmax(props)] += diff\n",
        "\n",
        "        start = 0\n",
        "        for k in range(n_clients):\n",
        "            client_indices[k].extend(idxs[start:start + counts[k]])\n",
        "            start += counts[k]\n",
        "\n",
        "    for k in range(n_clients):\n",
        "        random.shuffle(client_indices[k])\n",
        "    return client_indices\n",
        "\n",
        "\n",
        "def robust_client_splits(train_df, indices, val_frac, tune_frac):\n",
        "    idxs = np.array(indices, dtype=int)\n",
        "    if len(idxs) < 3:\n",
        "        return idxs.tolist(), idxs.tolist(), idxs.tolist()\n",
        "\n",
        "    yk = train_df.loc[idxs, \"y\"].values\n",
        "    if len(np.unique(yk)) < 2 or len(idxs) < 20:\n",
        "        n_tune = max(1, int(round(len(idxs) * tune_frac)))\n",
        "        n_tune = min(n_tune, max(1, len(idxs) - 2))\n",
        "        tune_idx = idxs[:n_tune]\n",
        "        rem_idx = idxs[n_tune:]\n",
        "    else:\n",
        "        rem_idx, tune_idx = train_test_split(idxs, test_size=tune_frac, stratify=yk, random_state=SEED)\n",
        "\n",
        "    if len(rem_idx) < 2:\n",
        "        return rem_idx.tolist(), tune_idx.tolist(), rem_idx.tolist()\n",
        "\n",
        "    yk2 = train_df.loc[rem_idx, \"y\"].values\n",
        "    if len(np.unique(yk2)) < 2 or len(rem_idx) < 12:\n",
        "        n_val = max(1, int(round(len(rem_idx) * val_frac)))\n",
        "        n_val = min(n_val, max(1, len(rem_idx) - 1))\n",
        "        val_idx = rem_idx[:n_val]\n",
        "        train_idx = rem_idx[n_val:]\n",
        "    else:\n",
        "        train_idx, val_idx = train_test_split(rem_idx, test_size=val_frac, stratify=yk2, random_state=SEED)\n",
        "\n",
        "    if len(train_idx) == 0:\n",
        "        train_idx = val_idx[:]\n",
        "    if len(val_idx) == 0:\n",
        "        val_idx = train_idx[:1]\n",
        "    return train_idx.tolist(), tune_idx.tolist(), val_idx.tolist()\n",
        "\n",
        "\n",
        "def load_rgb(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]), (128, 128, 128))\n",
        "\n",
        "\n",
        "EVAL_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "TRAIN_TFMS = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"img_size\"], CFG[\"img_size\"])),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, frame, indices=None, tfms=None):\n",
        "        self.df = frame\n",
        "        self.indices = indices if indices is not None else list(range(len(frame)))\n",
        "        self.tfms = tfms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        j = self.indices[i]\n",
        "        row = self.df.iloc[j]\n",
        "        img = load_rgb(row[\"path\"])\n",
        "        x = self.tfms(img) if self.tfms is not None else transforms.ToTensor()(img)\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y, row[\"path\"]\n",
        "\n",
        "\n",
        "def make_weighted_sampler(frame, indices, num_classes):\n",
        "    if len(indices) == 0:\n",
        "        return None\n",
        "    ys = frame.loc[indices, \"y\"].values\n",
        "    class_counts = np.bincount(ys, minlength=num_classes)\n",
        "    class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
        "    sample_weights = class_weights[ys]\n",
        "    return WeightedRandomSampler(\n",
        "        weights=torch.DoubleTensor(sample_weights),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_loader(frame, indices, bs, tfms, shuffle=False, sampler=None):\n",
        "    ds = MRIDataset(frame, indices=indices, tfms=tfms)\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=bs,\n",
        "        shuffle=(shuffle and sampler is None),\n",
        "        sampler=sampler,\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        pin_memory=(DEVICE.type == \"cuda\"),\n",
        "        drop_last=False,\n",
        "        persistent_workers=(CFG[\"num_workers\"] > 0),\n",
        "    )\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Preprocessing + GA\n",
        "# ============================================================\n",
        "\n",
        "class EnhancedFELCM(nn.Module):\n",
        "    def __init__(self, gamma=1.0, alpha=0.35, beta=6.0, tau=2.5, blur_k=7, sharpen=0.0, denoise=0.0):\n",
        "        super().__init__()\n",
        "        self.gamma = float(gamma)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.tau = float(tau)\n",
        "        self.blur_k = int(blur_k)\n",
        "        self.sharpen = float(sharpen)\n",
        "        self.denoise = float(denoise)\n",
        "\n",
        "        lap = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"lap\", lap.view(1, 1, 3, 3))\n",
        "\n",
        "        sharp = torch.tensor([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=torch.float32)\n",
        "        self.register_buffer(\"sharp_kernel\", sharp.view(1, 1, 3, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-6\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        if self.denoise > 0:\n",
        "            x_blur = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode=\"reflect\"), 3, 1)\n",
        "            x = x * (1 - self.denoise) + x_blur * self.denoise\n",
        "\n",
        "        mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "        sd = x.std(dim=(2, 3), keepdim=True).clamp_min(eps)\n",
        "        x0 = (x - mu) / sd\n",
        "        x0 = x0.clamp(-self.tau, self.tau)\n",
        "\n",
        "        x1 = torch.sign(x0) * torch.pow(torch.abs(x0).clamp_min(eps), self.gamma)\n",
        "\n",
        "        gray = x1.mean(dim=1, keepdim=True)\n",
        "        lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), self.lap)\n",
        "        mag = lap.abs()\n",
        "\n",
        "        k = self.blur_k if self.blur_k % 2 == 1 else self.blur_k + 1\n",
        "        pad = k // 2\n",
        "        blur = F.avg_pool2d(F.pad(mag, (pad, pad, pad, pad), mode=\"reflect\"), k, 1)\n",
        "        c_map = mag / (blur + eps)\n",
        "\n",
        "        x2 = x1 + self.alpha * torch.tanh(self.beta * c_map)\n",
        "\n",
        "        if self.sharpen > 0:\n",
        "            outs = []\n",
        "            for c in range(C):\n",
        "                x_c = x2[:, c:c + 1, :, :]\n",
        "                x_sharp = F.conv2d(F.pad(x_c, (1, 1, 1, 1), mode=\"reflect\"), self.sharp_kernel)\n",
        "                outs.append(x_c * (1 - self.sharpen) + x_sharp * self.sharpen)\n",
        "            x2 = torch.cat(outs, dim=1)\n",
        "\n",
        "        mn = x2.amin(dim=(2, 3), keepdim=True)\n",
        "        mx = x2.amax(dim=(2, 3), keepdim=True)\n",
        "        x3 = (x2 - mn) / (mx - mn + eps)\n",
        "        return x3.clamp(0, 1)\n",
        "\n",
        "\n",
        "def theta_to_module(theta):\n",
        "    return EnhancedFELCM(*theta)\n",
        "\n",
        "\n",
        "def random_theta():\n",
        "    return (\n",
        "        random.uniform(0.7, 1.4),\n",
        "        random.uniform(0.15, 0.55),\n",
        "        random.uniform(3.0, 9.0),\n",
        "        random.uniform(1.8, 3.2),\n",
        "        random.choice([3, 5, 7]),\n",
        "        random.uniform(0.0, 0.25),\n",
        "        random.uniform(0.0, 0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "def mutate(theta, p=0.8):\n",
        "    if random.random() > p:\n",
        "        return theta\n",
        "    g, a, b, t, k, sh, dn = theta\n",
        "    g = float(np.clip(g + np.random.normal(0, 0.06), 0.6, 1.5))\n",
        "    a = float(np.clip(a + np.random.normal(0, 0.05), 0.08, 0.7))\n",
        "    b = float(np.clip(b + np.random.normal(0, 0.5), 2.0, 11.0))\n",
        "    t = float(np.clip(t + np.random.normal(0, 0.2), 1.5, 3.8))\n",
        "    if random.random() < 0.3:\n",
        "        k = random.choice([3, 5, 7])\n",
        "    sh = float(np.clip(sh + np.random.normal(0, 0.04), 0.0, 0.35))\n",
        "    dn = float(np.clip(dn + np.random.normal(0, 0.03), 0.0, 0.3))\n",
        "    return (g, a, b, t, int(k), sh, dn)\n",
        "\n",
        "\n",
        "def crossover(t1, t2):\n",
        "    return tuple(random.choice([a, b]) for a, b in zip(t1, t2))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def enhanced_separability_score(emb, y):\n",
        "    eps = 1e-6\n",
        "    classes = torch.unique(y.long())\n",
        "    if len(classes) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids, within_vars, sizes = [], [], []\n",
        "    for c in classes:\n",
        "        e = emb[y == c]\n",
        "        if e.size(0) < 2:\n",
        "            continue\n",
        "        mu = e.mean(dim=0)\n",
        "        var = (e - mu).pow(2).sum(dim=1).mean().item()\n",
        "        centroids.append(mu)\n",
        "        within_vars.append(var)\n",
        "        sizes.append(e.size(0))\n",
        "\n",
        "    if len(centroids) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    centroids = torch.stack(centroids, dim=0)\n",
        "    global_mean = centroids.mean(dim=0)\n",
        "    between = sum(n * (c - global_mean).pow(2).sum().item() for c, n in zip(centroids, sizes))\n",
        "    within = float(np.mean(within_vars)) if within_vars else eps\n",
        "    return float(between / (within + eps))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ga_fitness(theta, backbone_frozen, batch_x, batch_y):\n",
        "    pre = theta_to_module(theta).to(DEVICE)\n",
        "    x = batch_x.to(DEVICE)\n",
        "    y = batch_y.to(DEVICE)\n",
        "\n",
        "    x_p = pre(x)\n",
        "    gray = x_p.mean(dim=1, keepdim=True)\n",
        "    lap = F.conv2d(F.pad(gray, (1, 1, 1, 1), mode=\"reflect\"), pre.lap).abs()\n",
        "    contrast = float(lap.mean().item())\n",
        "    dyn_range = float((x_p.max() - x_p.min()).item())\n",
        "\n",
        "    x_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    emb = backbone_frozen(x_n)\n",
        "    if isinstance(emb, (list, tuple)):\n",
        "        emb = emb[-1].mean(dim=(2, 3))\n",
        "\n",
        "    sep = enhanced_separability_score(emb, y)\n",
        "    g, a, b, t, _, sh, dn = theta\n",
        "    cost = 0.03 * abs(g - 1.0) + 0.05 * a + 0.01 * (b / 10.0) + 0.02 * abs(t - 2.5) + 0.02 * sh + 0.02 * dn\n",
        "    return 0.35 * contrast + 0.15 * dyn_range + 1.35 * sep - 0.5 * cost\n",
        "\n",
        "\n",
        "def run_ga_for_client(backbone_frozen, loader, elite_pool):\n",
        "    try:\n",
        "        bx, by, _ = next(iter(loader))\n",
        "    except Exception:\n",
        "        return None, [], 0.0\n",
        "\n",
        "    pop = []\n",
        "    if elite_pool:\n",
        "        pop.extend(elite_pool[: min(len(elite_pool), CFG[\"ga_pop\"] // 2)])\n",
        "    while len(pop) < CFG[\"ga_pop\"]:\n",
        "        pop.append(random_theta())\n",
        "\n",
        "    bx = bx[: CFG[\"batch_size\"]].contiguous()\n",
        "    by = by[: CFG[\"batch_size\"]].contiguous()\n",
        "\n",
        "    for _ in range(CFG[\"ga_gens\"]):\n",
        "        scored = [(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop]\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        elites = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "\n",
        "        new_pop = elites[:]\n",
        "        while len(new_pop) < CFG[\"ga_pop\"]:\n",
        "            p1, p2 = random.sample(elites + pop[: max(2, CFG[\"ga_pop\"] // 2)], 2)\n",
        "            new_pop.append(mutate(crossover(p1, p2), p=0.75))\n",
        "        pop = new_pop\n",
        "\n",
        "    scored = [(ga_fitness(th, backbone_frozen, bx, by), th) for th in pop]\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_theta = scored[0][1]\n",
        "    top = [th for _, th in scored[: CFG[\"ga_elites\"]]]\n",
        "    return best_theta, top, float(scored[0][0])\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Model\n",
        "# ============================================================\n",
        "\n",
        "BACKBONE_NAME = \"pvt_v2_b2\"\n",
        "\n",
        "\n",
        "class TokenAttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.softmax(self.query(x).squeeze(-1), dim=1)\n",
        "        return (x * attn.unsqueeze(-1)).sum(dim=1)\n",
        "\n",
        "\n",
        "class MultiScaleFeatureFuser(nn.Module):\n",
        "    def __init__(self, in_channels: List[int], out_dim: int):\n",
        "        super().__init__()\n",
        "        self.proj = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(c, out_dim, kernel_size=1, bias=False),\n",
        "                nn.GroupNorm(8, out_dim),\n",
        "                nn.GELU(),\n",
        "            )\n",
        "            for c in in_channels\n",
        "        ])\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(8, out_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.pool = TokenAttentionPooling(out_dim)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        proj_feats = [p(f) for p, f in zip(self.proj, feats)]\n",
        "        x = proj_feats[-1]\n",
        "        for f in reversed(proj_feats[:-1]):\n",
        "            x = F.interpolate(x, size=f.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "            x = x + f\n",
        "        x = self.fuse(x)\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        return self.pool(tokens)\n",
        "\n",
        "\n",
        "class EnhancedBrainTuner(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.Linear(dim, max(8, dim // 4)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(max(8, dim // 4), dim),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.refine = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.gate = nn.Parameter(torch.ones(2) / 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate = F.softmax(self.gate, dim=0)\n",
        "        out1 = x * self.se(x)\n",
        "        out2 = x + 0.2 * self.refine(x)\n",
        "        return gate[0] * out1 + gate[1] * out2\n",
        "\n",
        "\n",
        "class PVTv2B2_MultiScale_NoConditioning(nn.Module):\n",
        "    \"\"\"\n",
        "    Keep gate mechanism but remove conditioning signal:\n",
        "      - theta_vec is ignored\n",
        "      - source_id is ignored\n",
        "      - client_id is ignored\n",
        "      - shared zero conditioning vector is used for all samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True, head_dropout=0.3, cond_dim=128):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            BACKBONE_NAME,\n",
        "            pretrained=pretrained,\n",
        "            features_only=True,\n",
        "            out_indices=(0, 1, 2, 3),\n",
        "        )\n",
        "        in_channels = self.backbone.feature_info.channels()\n",
        "        out_dim = max(256, in_channels[-1] // 2)\n",
        "\n",
        "        self.fuser = MultiScaleFeatureFuser(in_channels, out_dim)\n",
        "        self.tuner = EnhancedBrainTuner(out_dim, dropout=0.1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(head_dropout),\n",
        "            nn.Linear(out_dim, max(64, out_dim // 2)),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(head_dropout * 0.5),\n",
        "            nn.Linear(max(64, out_dim // 2), num_classes),\n",
        "        )\n",
        "\n",
        "        self.cond_norm = nn.LayerNorm(cond_dim)\n",
        "        self.gate_early = nn.Linear(cond_dim, 3)\n",
        "        self.gate_mid = nn.Linear(cond_dim, out_dim)\n",
        "        self.gate_late = nn.Linear(cond_dim, out_dim)\n",
        "\n",
        "    def _zero_cond_vec(self, batch_size, device):\n",
        "        z = torch.zeros(batch_size, self.cond_norm.normalized_shape[0], device=device, dtype=torch.float32)\n",
        "        return self.cond_norm(z)\n",
        "\n",
        "    def forward(self, x_raw_n, x_fel_n, theta_vec, source_id, client_id):\n",
        "        cond = self._zero_cond_vec(x_raw_n.size(0), x_raw_n.device)\n",
        "\n",
        "        g0 = torch.sigmoid(self.gate_early(cond)).view(-1, 3, 1, 1)\n",
        "        x0 = (1 - g0) * x_raw_n + g0 * x_fel_n\n",
        "\n",
        "        feats0 = self.backbone(x0)\n",
        "        feats1 = self.backbone(x_fel_n)\n",
        "\n",
        "        f0 = self.fuser(feats0)\n",
        "        f1 = self.fuser(feats1)\n",
        "\n",
        "        g1 = torch.sigmoid(self.gate_mid(cond))\n",
        "        f_mid = (1 - g1) * f0 + g1 * f1\n",
        "\n",
        "        t0 = self.tuner(f0)\n",
        "        t1 = self.tuner(f1)\n",
        "        t_mid = self.tuner(f_mid)\n",
        "\n",
        "        t_views = 0.5 * (t0 + t1)\n",
        "        g2 = torch.sigmoid(self.gate_late(cond))\n",
        "        t_final = (1 - g2) * t_mid + g2 * t_views\n",
        "\n",
        "        return self.classifier(t_final)\n",
        "\n",
        "\n",
        "def set_trainable_for_round(model, rnd):\n",
        "    for p in model.backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "    for n, p in model.named_parameters():\n",
        "        if not n.startswith(\"backbone.\"):\n",
        "            p.requires_grad = True\n",
        "    if rnd >= CFG[\"unfreeze_after_round\"]:\n",
        "        params = list(model.backbone.parameters())\n",
        "        tail_n = max(1, int(len(params) * CFG[\"unfreeze_tail_frac\"]))\n",
        "        for p in params[-tail_n:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params, bb_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        if n.startswith(\"backbone.\"):\n",
        "            bb_params.append(p)\n",
        "        else:\n",
        "            head_params.append(p)\n",
        "    groups = []\n",
        "    if head_params:\n",
        "        groups.append({\"params\": head_params, \"lr\": CFG[\"lr\"]})\n",
        "    if bb_params:\n",
        "        groups.append({\"params\": bb_params, \"lr\": CFG[\"lr\"] * CFG[\"unfreeze_lr_mult\"]})\n",
        "    return torch.optim.AdamW(groups, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < num_warmup_steps:\n",
        "            return float(step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def preproc_theta_vec(batch_size):\n",
        "    # Explicit ablation: theta_vec = zeros for all samples\n",
        "    return torch.zeros(batch_size, 7, device=DEVICE, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def zero_source_client_ids(batch_size):\n",
        "    # Explicit ablation: source_id = 0, client_id = 0 for all samples\n",
        "    z = torch.zeros(batch_size, device=DEVICE, dtype=torch.long)\n",
        "    return z, z\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _auc_metrics(y_true, p_pred, num_classes):\n",
        "    out = {}\n",
        "    try:\n",
        "        if num_classes == 2:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred[:, 1]))\n",
        "        else:\n",
        "            out[\"auc_roc_macro_ovr\"] = float(roc_auc_score(y_true, p_pred, multi_class=\"ovr\", average=\"macro\"))\n",
        "    except Exception:\n",
        "        out[\"auc_roc_macro_ovr\"] = np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full(model, loader, preproc_module, num_classes):\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    all_y, all_p, all_loss = [], [], []\n",
        "    has_any = False\n",
        "\n",
        "    for x, y, _ in loader:\n",
        "        has_any = True\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        x_p = preproc_module(x)\n",
        "        x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "\n",
        "        theta_vec = preproc_theta_vec(x.size(0))\n",
        "        source_id, client_id = zero_source_client_ids(x.size(0))\n",
        "\n",
        "        logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        all_loss.append(float(loss.item()))\n",
        "        all_y.append(y.detach().cpu().numpy())\n",
        "        all_p.append(probs.detach().cpu().numpy())\n",
        "\n",
        "    if not has_any:\n",
        "        return {\n",
        "            \"acc\": np.nan,\n",
        "            \"precision_macro\": np.nan,\n",
        "            \"recall_macro\": np.nan,\n",
        "            \"f1_macro\": np.nan,\n",
        "            \"precision_weighted\": np.nan,\n",
        "            \"recall_weighted\": np.nan,\n",
        "            \"f1_weighted\": np.nan,\n",
        "            \"log_loss\": np.nan,\n",
        "            \"auc_roc_macro_ovr\": np.nan,\n",
        "            \"loss_ce\": np.nan,\n",
        "            \"eval_time_s\": float(time.time() - t0),\n",
        "        }, np.array([]), np.array([])\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    p_pred = np.concatenate(all_p)\n",
        "    y_hat = np.argmax(p_pred, axis=1)\n",
        "\n",
        "    met = {\n",
        "        \"acc\": float(accuracy_score(y_true, y_hat)),\n",
        "        \"precision_macro\": float(precision_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"recall_macro\": float(recall_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"f1_macro\": float(f1_score(y_true, y_hat, average=\"macro\", zero_division=0)),\n",
        "        \"precision_weighted\": float(precision_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"recall_weighted\": float(recall_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"f1_weighted\": float(f1_score(y_true, y_hat, average=\"weighted\", zero_division=0)),\n",
        "        \"log_loss\": float(log_loss(y_true, p_pred, labels=list(range(num_classes)))),\n",
        "        \"loss_ce\": float(np.mean(all_loss)),\n",
        "        \"eval_time_s\": float(time.time() - t0),\n",
        "    }\n",
        "    met.update(_auc_metrics(y_true, p_pred, num_classes))\n",
        "    return met, y_true, p_pred\n",
        "\n",
        "\n",
        "def fedprox_term(local_model, global_model):\n",
        "    loss = 0.0\n",
        "    for p_local, p_global in zip(local_model.parameters(), global_model.parameters()):\n",
        "        loss += ((p_local - p_global.detach()) ** 2).sum()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, preproc_module, criterion, global_model=None, scheduler=None, scaler=None):\n",
        "    model.train()\n",
        "    preproc_module.eval()\n",
        "\n",
        "    for x, y, _ in loader:\n",
        "        x = x.to(DEVICE, non_blocking=True)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=DEVICE.type, enabled=(scaler is not None)):\n",
        "            x_p = preproc_module(x)\n",
        "            x_raw_n = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            x_fel_n = (x_p - IMAGENET_MEAN) / IMAGENET_STD\n",
        "            theta_vec = preproc_theta_vec(x.size(0))\n",
        "            source_id, client_id = zero_source_client_ids(x.size(0))\n",
        "            logits = model(x_raw_n, x_fel_n, theta_vec, source_id, client_id)\n",
        "            loss = criterion(logits, y)\n",
        "            if global_model is not None and CFG[\"fedprox_mu\"] > 0:\n",
        "                loss = loss + 0.5 * CFG[\"fedprox_mu\"] * fedprox_term(model, global_model)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if CFG[\"grad_clip\"] > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if CFG[\"grad_clip\"] > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "def fedavg_update(global_model, local_models, weights, trainable_names):\n",
        "    gsd = global_model.state_dict()\n",
        "    for name in trainable_names:\n",
        "        acc = None\n",
        "        for m, w in zip(local_models, weights):\n",
        "            p = m.state_dict()[name].detach().float().cpu()\n",
        "            acc = (w * p) if acc is None else (acc + w * p)\n",
        "        gsd[name].copy_(acc.to(gsd[name].device).type_as(gsd[name]))\n",
        "    global_model.load_state_dict(gsd)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def pick_best_theta_from_pool(model, pool, val_loader, num_classes, max_candidates=10):\n",
        "    if not pool:\n",
        "        return None\n",
        "    best, best_acc = None, -1\n",
        "    for th in pool[:max_candidates]:\n",
        "        pre = theta_to_module(th).to(DEVICE)\n",
        "        met, _, _ = evaluate_full(model, val_loader, pre, num_classes)\n",
        "        if np.isfinite(met[\"acc\"]) and met[\"acc\"] > best_acc:\n",
        "            best_acc = met[\"acc\"]\n",
        "            best = th\n",
        "    return best\n",
        "\n",
        "\n",
        "def weighted_aggregate(mets: List[Tuple[int, dict, int]]):\n",
        "    if not mets:\n",
        "        return {}\n",
        "    total = sum(w for _, _, w in mets)\n",
        "    if total == 0:\n",
        "        return {}\n",
        "    out = {}\n",
        "    for k in mets[0][1].keys():\n",
        "        vals = [m[1].get(k, np.nan) for m in mets]\n",
        "        ws = [m[2] for m in mets]\n",
        "        out[k] = float(np.average(vals, weights=ws))\n",
        "    return out\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Main\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    ds2_path = kagglehub.dataset_download(\"yassinebazgour/preprocessed-brain-mri-scans-for-tumors-detection\")\n",
        "    ds1_path = kagglehub.dataset_download(\"orvile/pmram-bangladeshi-brain-cancer-mri-dataset\")\n",
        "\n",
        "    req1 = {\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"}\n",
        "    req2 = {\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"}\n",
        "\n",
        "    ds1_root = find_root_with_required_class_dirs(ds1_path, req1, prefer_raw=True)\n",
        "    ds2_root = find_root_with_required_class_dirs(ds2_path, req2, prefer_raw=False)\n",
        "    if ds1_root is None or ds2_root is None:\n",
        "        raise RuntimeError(\"Could not locate dataset roots\")\n",
        "\n",
        "    df1 = build_df_from_root(ds1_root, [\"512Glioma\", \"512Meningioma\", \"512Normal\", \"512Pituitary\"], \"ds1_raw\")\n",
        "    df2 = build_df_from_root(ds2_root, [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"], \"ds2\")\n",
        "\n",
        "    labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "    label2id = {l: i for i, l in enumerate(labels)}\n",
        "    num_classes = len(labels)\n",
        "\n",
        "    df1 = enforce_labels(df1, labels, label2id)\n",
        "    df2 = enforce_labels(df2, labels, label2id)\n",
        "\n",
        "    train1, val1, test1 = split_dataset(df1)\n",
        "    train2, val2, test2 = split_dataset(df2)\n",
        "\n",
        "    n_per_ds = CFG[\"clients_per_dataset\"]\n",
        "    client_indices_ds1 = make_clients_non_iid(train1, n_per_ds, num_classes, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "    client_indices_ds2 = make_clients_non_iid(train2, n_per_ds, num_classes, CFG[\"min_per_class_per_client\"], CFG[\"dirichlet_alpha\"])\n",
        "\n",
        "    client_splits = []\n",
        "    for k in range(n_per_ds):\n",
        "        tr, tune, va = robust_client_splits(train1, client_indices_ds1[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "        client_splits.append((\"ds1\", k, tr, tune, va))\n",
        "    for k in range(n_per_ds):\n",
        "        tr, tune, va = robust_client_splits(train2, client_indices_ds2[k], CFG[\"client_val_frac\"], CFG[\"client_tune_frac\"])\n",
        "        client_splits.append((\"ds2\", k, tr, tune, va))\n",
        "\n",
        "    client_test_splits = []\n",
        "    for ds_name, test_df in [(\"ds1\", test1), (\"ds2\", test2)]:\n",
        "        idxs = list(range(len(test_df)))\n",
        "        random.shuffle(idxs)\n",
        "        split = np.array_split(idxs, n_per_ds)\n",
        "        for k in range(n_per_ds):\n",
        "            client_test_splits.append((ds_name, k, split[k].tolist()))\n",
        "\n",
        "    client_loaders = []\n",
        "    for ds_name, _, tr_idx, tune_idx, val_idx in client_splits:\n",
        "        df_src = train1 if ds_name == \"ds1\" else train2\n",
        "        sampler = make_weighted_sampler(df_src, tr_idx, num_classes)\n",
        "        tr_loader = make_loader(df_src, tr_idx, CFG[\"batch_size\"], TRAIN_TFMS, shuffle=(sampler is None), sampler=sampler)\n",
        "        tune_loader = make_loader(df_src, tune_idx if len(tune_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=True)\n",
        "        val_loader = make_loader(df_src, val_idx if len(val_idx) else tr_idx[:1], CFG[\"batch_size\"], EVAL_TFMS, shuffle=False)\n",
        "        client_loaders.append((tr_loader, tune_loader, val_loader))\n",
        "\n",
        "    client_test_loaders = []\n",
        "    for ds_name, local_id, test_idx in client_test_splits:\n",
        "        df_src = test1 if ds_name == \"ds1\" else test2\n",
        "        t_loader = make_loader(df_src, test_idx, CFG[\"batch_size\"], EVAL_TFMS, shuffle=False)\n",
        "        client_test_loaders.append((ds_name, local_id, t_loader))\n",
        "\n",
        "    global_model = PVTv2B2_MultiScale_NoConditioning(\n",
        "        num_classes=num_classes,\n",
        "        pretrained=True,\n",
        "        head_dropout=0.3,\n",
        "        cond_dim=128,\n",
        "    ).to(DEVICE)\n",
        "    set_trainable_for_round(global_model, rnd=1)\n",
        "\n",
        "    backbone_frozen = global_model.backbone.eval()\n",
        "    for p in backbone_frozen.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    counts1 = train1[\"y\"].value_counts().sort_index().reindex(range(num_classes), fill_value=0).values\n",
        "    counts2 = train2[\"y\"].value_counts().sort_index().reindex(range(num_classes), fill_value=0).values\n",
        "    counts = counts1 + counts2\n",
        "    w = (counts.sum() / np.clip(counts, 1, None)).astype(np.float32)\n",
        "    w = w / max(1e-6, w.mean())\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(w, device=DEVICE), label_smoothing=CFG[\"label_smoothing\"])\n",
        "    scaler = torch.amp.GradScaler(\"cuda\") if DEVICE.type == \"cuda\" else None\n",
        "\n",
        "    elite_pool_ds1, elite_pool_ds2 = [], []\n",
        "    best_global_acc = -1.0\n",
        "    best_model_state = None\n",
        "    best_theta_ds1 = None\n",
        "    best_theta_ds2 = None\n",
        "\n",
        "    for rnd in range(1, CFG[\"rounds\"] + 1):\n",
        "        local_models, local_weights, local_rows = [], [], []\n",
        "\n",
        "        for k in range(CFG[\"clients_total\"]):\n",
        "            tr_loader, tune_loader, val_loader = client_loaders[k]\n",
        "            ds_name = \"ds1\" if k < n_per_ds else \"ds2\"\n",
        "            elite_pool = elite_pool_ds1 if ds_name == \"ds1\" else elite_pool_ds2\n",
        "\n",
        "            if CFG[\"use_preprocessing\"] and CFG[\"use_ga\"]:\n",
        "                best_theta, top_thetas, _ = run_ga_for_client(backbone_frozen, tune_loader, elite_pool)\n",
        "                elite_pool.extend(top_thetas)\n",
        "                elite_pool[:] = elite_pool[: CFG[\"elite_pool_max\"]]\n",
        "                pre_k = theta_to_module(best_theta).to(DEVICE) if best_theta is not None else nn.Identity().to(DEVICE)\n",
        "            else:\n",
        "                pre_k = nn.Identity().to(DEVICE)\n",
        "\n",
        "            if ds_name == \"ds1\":\n",
        "                elite_pool_ds1 = elite_pool\n",
        "            else:\n",
        "                elite_pool_ds2 = elite_pool\n",
        "\n",
        "            local_model = PVTv2B2_MultiScale_NoConditioning(\n",
        "                num_classes=num_classes,\n",
        "                pretrained=False,\n",
        "                head_dropout=0.3,\n",
        "                cond_dim=128,\n",
        "            ).to(DEVICE)\n",
        "            local_model.load_state_dict(global_model.state_dict(), strict=True)\n",
        "\n",
        "            set_trainable_for_round(local_model, rnd=rnd)\n",
        "            opt = make_optimizer(local_model)\n",
        "            total_steps = max(1, len(tr_loader) * CFG[\"local_epochs\"])\n",
        "            warmup_steps = max(1, len(tr_loader) * CFG[\"warmup_epochs\"])\n",
        "            scheduler = get_cosine_schedule_with_warmup(opt, warmup_steps, total_steps)\n",
        "\n",
        "            for _ in range(CFG[\"local_epochs\"]):\n",
        "                train_one_epoch(local_model, tr_loader, opt, pre_k, criterion, global_model, scheduler, scaler)\n",
        "\n",
        "            met_loc, _, _ = evaluate_full(local_model, val_loader, pre_k, num_classes)\n",
        "            local_rows.append({\"val_acc\": met_loc[\"acc\"]})\n",
        "            local_models.append(local_model)\n",
        "            local_weights.append(len(tr_loader.dataset))\n",
        "\n",
        "        wsum = sum(local_weights)\n",
        "        weights = [w / wsum for w in local_weights]\n",
        "        trainable_names = [n for n, p in local_models[0].named_parameters() if p.requires_grad]\n",
        "        fedavg_update(global_model, local_models, weights, trainable_names)\n",
        "\n",
        "        local_val_rows = pd.DataFrame(local_rows)\n",
        "        global_val_acc = float(local_val_rows[\"val_acc\"].mean()) if len(local_val_rows) else np.nan\n",
        "\n",
        "        if CFG[\"use_preprocessing\"] and elite_pool_ds1:\n",
        "            best_theta_ds1 = pick_best_theta_from_pool(global_model, elite_pool_ds1, client_loaders[0][2], num_classes)\n",
        "        if CFG[\"use_preprocessing\"] and elite_pool_ds2:\n",
        "            best_theta_ds2 = pick_best_theta_from_pool(global_model, elite_pool_ds2, client_loaders[n_per_ds][2], num_classes)\n",
        "\n",
        "        if np.isfinite(global_val_acc) and global_val_acc > best_global_acc:\n",
        "            best_global_acc = global_val_acc\n",
        "            best_model_state = {k: v.detach().cpu().clone() for k, v in global_model.state_dict().items()}\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        global_model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_state.items()})\n",
        "\n",
        "    pre_best_ds1 = theta_to_module(best_theta_ds1).to(DEVICE) if (best_theta_ds1 is not None) else nn.Identity().to(DEVICE)\n",
        "    pre_best_ds2 = theta_to_module(best_theta_ds2).to(DEVICE) if (best_theta_ds2 is not None) else nn.Identity().to(DEVICE)\n",
        "\n",
        "    # Federated VAL\n",
        "    val_metrics_clients = []\n",
        "    for k in range(CFG[\"clients_total\"]):\n",
        "        _, _, val_loader = client_loaders[k]\n",
        "        pre = pre_best_ds1 if k < n_per_ds else pre_best_ds2\n",
        "        met, _, _ = evaluate_full(global_model, val_loader, pre, num_classes)\n",
        "        val_metrics_clients.append((k, met, len(val_loader.dataset)))\n",
        "    val_best = weighted_aggregate(val_metrics_clients)\n",
        "\n",
        "    # Federated TEST per dataset\n",
        "    def eval_test_per_dataset(ds_name):\n",
        "        mets = []\n",
        "        for ds, _, t_loader in client_test_loaders:\n",
        "            if ds != ds_name:\n",
        "                continue\n",
        "            pre = pre_best_ds1 if ds == \"ds1\" else pre_best_ds2\n",
        "            met, _, _ = evaluate_full(global_model, t_loader, pre, num_classes)\n",
        "            mets.append((met, len(t_loader.dataset)))\n",
        "        if not mets:\n",
        "            return {}\n",
        "        return weighted_aggregate([(i, m[0], m[1]) for i, m in enumerate(mets)])\n",
        "\n",
        "    test_ds1 = eval_test_per_dataset(\"ds1\")\n",
        "    test_ds2 = eval_test_per_dataset(\"ds2\")\n",
        "    global_test = weighted_aggregate([\n",
        "        (0, test_ds1, len(test1)),\n",
        "        (1, test_ds2, len(test2)),\n",
        "    ])\n",
        "\n",
        "    wanted_cols = [\n",
        "        \"setting\",\n",
        "        \"split\",\n",
        "        \"dataset\",\n",
        "        \"acc\",\n",
        "        \"precision_macro\",\n",
        "        \"recall_macro\",\n",
        "        \"f1_macro\",\n",
        "        \"precision_weighted\",\n",
        "        \"recall_weighted\",\n",
        "        \"f1_weighted\",\n",
        "        \"log_loss\",\n",
        "        \"auc_roc_macro_ovr\",\n",
        "        \"loss_ce\",\n",
        "        \"eval_time_s\",\n",
        "    ]\n",
        "\n",
        "    def row(setting, split, dataset, m):\n",
        "        return {\n",
        "            \"setting\": setting,\n",
        "            \"split\": split,\n",
        "            \"dataset\": dataset,\n",
        "            \"acc\": float(m.get(\"acc\", np.nan)),\n",
        "            \"precision_macro\": float(m.get(\"precision_macro\", np.nan)),\n",
        "            \"recall_macro\": float(m.get(\"recall_macro\", np.nan)),\n",
        "            \"f1_macro\": float(m.get(\"f1_macro\", np.nan)),\n",
        "            \"precision_weighted\": float(m.get(\"precision_weighted\", np.nan)),\n",
        "            \"recall_weighted\": float(m.get(\"recall_weighted\", np.nan)),\n",
        "            \"f1_weighted\": float(m.get(\"f1_weighted\", np.nan)),\n",
        "            \"log_loss\": float(m.get(\"log_loss\", np.nan)),\n",
        "            \"auc_roc_macro_ovr\": float(m.get(\"auc_roc_macro_ovr\", np.nan)),\n",
        "            \"loss_ce\": float(m.get(\"loss_ce\", np.nan)),\n",
        "            \"eval_time_s\": float(m.get(\"eval_time_s\", np.nan)),\n",
        "        }\n",
        "\n",
        "    out_df = pd.DataFrame([\n",
        "        row(\"No conditioning (theta/source/client forced to zero)\", \"VAL\", \"ds1+ds2 weighted\", val_best),\n",
        "        row(\"No conditioning (theta/source/client forced to zero)\", \"TEST\", \"ds1\", test_ds1),\n",
        "        row(\"No conditioning (theta/source/client forced to zero)\", \"TEST\", \"ds2\", test_ds2),\n",
        "        row(\"No conditioning (theta/source/client forced to zero)\", \"TEST\", \"global weighted\", global_test),\n",
        "    ])[wanted_cols]\n",
        "\n",
        "    out_df.to_csv(CSV_PATH, index=False)\n",
        "\n",
        "    checkpoint = {\n",
        "        \"state_dict\": {k: v.detach().cpu() for k, v in global_model.state_dict().items()},\n",
        "        \"config\": CFG,\n",
        "        \"seed\": SEED,\n",
        "        \"device_used\": str(DEVICE),\n",
        "        \"best_theta_ds1\": best_theta_ds1,\n",
        "        \"best_theta_ds2\": best_theta_ds2,\n",
        "        \"final_metrics\": out_df.to_dict(orient=\"records\"),\n",
        "    }\n",
        "    torch.save(checkpoint, MODEL_PATH)\n",
        "\n",
        "    print(out_df)\n",
        "    print(f\"Saved: {CSV_PATH}\")\n",
        "    print(f\"Saved: {MODEL_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}